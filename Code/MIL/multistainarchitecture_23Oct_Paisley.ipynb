{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iILjky4pEAdG"
      },
      "outputs": [],
      "source": [
        "# Standard library imports\n",
        "import os\n",
        "import re\n",
        "import random\n",
        "import shutil\n",
        "from datetime import datetime\n",
        "from collections import OrderedDict\n",
        "\n",
        "# Data handling and visualization libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# PyTorch and TorchVision libraries for deep learning\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import torchvision\n",
        "import torchvision.models as models\n",
        "from torchvision import transforms, datasets\n",
        "from PIL import Image\n",
        "\n",
        "# Scikit-Learn for evaluation metrics and data splitting|\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
        "\n",
        "# Imbalanced-learn for oversampling to address class imbalance\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "\n",
        "from torchvision import transforms\n",
        "from torchvision.transforms import functional as F\n",
        "from PIL import Image\n",
        "from PIL import Image\n",
        "from PIL import UnidentifiedImageError\n",
        "from tqdm import tqdm\n",
        "\n",
        "import os, re, random\n",
        "from collections import defaultdict, Counter\n",
        "from sklearn.model_selection import train_test_split\n",
        "from google.colab import drive\n",
        "from typing import List, Dict, Any, Tuple, Optional"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ctwMSZTEK9M",
        "outputId": "74fad9dd-d242-475c-a05b-a81978c3f879"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# â”€â”€â”€ 1) MOUNT GOOGLE DRIVE â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vGs2GP7zFypq"
      },
      "outputs": [],
      "source": [
        "# â”€â”€â”€ LOAD LABELS & BUILD CLASS MAP â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "labels = pd.read_csv(\n",
        "    \"/content/drive/MyDrive/case_grade_match.csv\"\n",
        ").drop(index=64, errors='ignore').reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "K2KupvZ1GBIU",
        "outputId": "64be0545-f851-4f75-9de3-6fd21702df98"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Case  Class\n",
              "62    63      3\n",
              "63    64      3\n",
              "64    66      3\n",
              "65    67      4"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-28a56b0e-8592-4df5-a3b9-068ba2adfceb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Case</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>63</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>64</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>66</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65</th>\n",
              "      <td>67</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-28a56b0e-8592-4df5-a3b9-068ba2adfceb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-28a56b0e-8592-4df5-a3b9-068ba2adfceb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-28a56b0e-8592-4df5-a3b9-068ba2adfceb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-ddc1bccc-f4fc-411e-929e-466bd5548a4c\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ddc1bccc-f4fc-411e-929e-466bd5548a4c')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-ddc1bccc-f4fc-411e-929e-466bd5548a4c button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"labels\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"Case\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 63,\n        \"max\": 67,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          64,\n          67,\n          63\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Class\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 3,\n        \"max\": 4,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          4,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "# Note that case 65 is not included in the analysis as it was not labelled\n",
        "labels.loc[62:65,:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0iD1oVfPwUp8",
        "outputId": "99c47a23-cd25-48d5-d743-e80b5a120616"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "83717"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "filtered_patches_dir = '/content/drive/MyDrive/CMIL_SP2025_Patches_Apr27'\n",
        "\n",
        "if os.path.exists(\"/content/drive/MyDrive/patch_dir.npy\"):\n",
        "    all_files = np.load(\"/content/drive/MyDrive/patch_dir.npy\", allow_pickle=True).tolist()\n",
        "else:\n",
        "    all_files = os.listdir('/content/drive/MyDrive/CMIL_SP2025_Patches_Apr27')\n",
        "\n",
        "len(all_files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vBovTKpdPl5D"
      },
      "outputs": [],
      "source": [
        "# === Slice-Level Grouping ===\n",
        "\n",
        "# Edit 10/19: identified scenario where patches are not being matched:\n",
        "#     1) missing space between 'match' / 'unmatched' and number, eg. case_38_match14_h&e_patch25.png\n",
        "#     2) Additionally, some names include 'labels' (not relevant to this regex which is only looking at case matching but thought I would flag),\n",
        "#         eg. case_82_unmatched3_h&e-labels_patch32.png\n",
        "def group_patches_by_slice(all_files, root):\n",
        "    case_slices = defaultdict(list)\n",
        "    # list of unconventionally-named patches\n",
        "    invalid_file_names = []\n",
        "    flexibility_needed_counter = 0\n",
        "    for filename in all_files:\n",
        "        if filename.endswith(\".png\"):\n",
        "            match = re.match(r\"case_(\\d+)_([a-z]+_\\d+)_\", filename) #check if some patches are named differently\n",
        "            if match:\n",
        "                case_id = int(match.group(1))\n",
        "                slice_id = match.group(2)\n",
        "                key = (case_id, slice_id)\n",
        "                case_slices[key].append(os.path.join(root, filename))\n",
        "\n",
        "                continue\n",
        "            # if a file doesn't match, try regex without \"_\" between \"match\" / \"unmatched\" and number\n",
        "            match = re.match(r\"case_(\\d+)_([a-z]+\\d+)_\", filename)\n",
        "            if match:\n",
        "                case_id = int(match.group(1))\n",
        "                slice_id = match.group(2)\n",
        "                # adding underscore between \"match\" / \"unmatched\" and number\n",
        "                slice_id = re.sub(r'([A-Za-z])(\\d)', r'\\1_\\2', slice_id)\n",
        "                key = (case_id, slice_id)\n",
        "                case_slices[key].append(os.path.join(root, filename))\n",
        "                flexibility_needed_counter += 1\n",
        "\n",
        "                continue\n",
        "            invalid_file_names.append(os.path.join(root, filename))\n",
        "\n",
        "    # Print summary of invalid files\n",
        "    if invalid_file_names:\n",
        "        print(f\"Found {len(invalid_file_names)} files not following naming convention:\")\n",
        "        for f in invalid_file_names:\n",
        "            print(\"  \", f)\n",
        "    else:\n",
        "        print(f\"All {flexibility_needed_counter} invalid file names were handled.\")\n",
        "    return case_slices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O33OgeH8PpTs",
        "outputId": "aa2af376-c7f0-47e9-f8f3-4a9d99f0778b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All 3808 invalid file names were handled.\n"
          ]
        }
      ],
      "source": [
        "# === Load Patches by Slice ===\n",
        "patches = group_patches_by_slice(all_files, filtered_patches_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ZOnUpxTbnrW",
        "outputId": "ff26b6f4-3b59-4b1e-9d5d-9ebe65f8779b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "378"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "len(patches)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B5hT39kHRPuG",
        "outputId": "65821cc5-7f80-430c-c251-6fd858654f3d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "83717"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "tot_patches = 0\n",
        "for ke in patches.keys():\n",
        "  tot_patches = tot_patches + len(patches[ke])\n",
        "tot_patches"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kAGh7_L2XOdZ"
      },
      "source": [
        "Some patches are getting lost (need to make the 'match = re.match(....)' code more general)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dklmcj3LTZbg"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2F55HKGHTfes"
      },
      "outputs": [],
      "source": [
        "# Training transform (augmented)\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JvuJRLKnTdXG"
      },
      "outputs": [],
      "source": [
        "# === Build Label Map by Slice ===\n",
        "slice_to_class = {}\n",
        "valid_classes = [1.0, 3.0, 4.0]\n",
        "for (case_id, slice_id), paths in patches.items():\n",
        "    raw_label = labels.loc[labels['Case'] == case_id, 'Class']\n",
        "    if not raw_label.empty and raw_label.item() in valid_classes:\n",
        "        label = 0 if raw_label.item() == 1.0 else 1\n",
        "        slice_to_class[(case_id, slice_id)] = label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dnPMgZEVaArv",
        "outputId": "70f3df33-20da-415b-b771-197383974a2e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "366"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "len(slice_to_class) # Low-grade slices are removed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iMd2EPH8clyX",
        "outputId": "f6087b0a-f17b-468b-d28b-81f869ff9cbb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "slice_to_class[(106, 'match_1')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mHOQiVV-czTU"
      },
      "outputs": [],
      "source": [
        "# === Stratified Split by Slice ===\n",
        "slices_by_class = defaultdict(list)\n",
        "for key, label in slice_to_class.items():\n",
        "    slices_by_class[label].append(key) # Dictonary of length 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PcRR60GYc4He",
        "outputId": "3e3fe81e-e056-423a-d939-94a4d3fe3ad1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys([1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ],
      "source": [
        "slices_by_class.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bYt7GPXodEww",
        "outputId": "92b97f24-35b1-41af-fa88-98c5f88c4c37"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "86"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ],
      "source": [
        "# number of cases\n",
        "unique_case = {t[0] for v in slices_by_class.values() for t in v}\n",
        "len(unique_case)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D1tz-StATKNd"
      },
      "outputs": [],
      "source": [
        "def split_by_case_stratified(slices_by_class, random_state=42):\n",
        "    # 1) Build case -> label map and validate no mixed-label cases\n",
        "    case_to_labels = defaultdict(set)\n",
        "    for label, items in slices_by_class.items():\n",
        "        for case_id, _ in items:\n",
        "            case_to_labels[case_id].add(label)\n",
        "\n",
        "    # Flatten to case list and aligned labels\n",
        "    case_ids = []\n",
        "    case_labels = []\n",
        "    for cid, labs in case_to_labels.items():\n",
        "        case_ids.append(cid)\n",
        "        case_labels.append(next(iter(labs)))  # the single label for this case\n",
        "\n",
        "    # 2) Split cases with stratification by case-level label\n",
        "    # 60% train, 40% temp\n",
        "    case_train, case_temp, y_train, y_temp = train_test_split(\n",
        "        case_ids, case_labels, test_size=0.4, stratify=case_labels, random_state=random_state\n",
        "    )\n",
        "    # temp -> 50/50 to make 20%/20% val/test\n",
        "    case_val, case_test, _, _ = train_test_split(\n",
        "        case_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=random_state\n",
        "    )\n",
        "\n",
        "    case_train = set(case_train)\n",
        "    case_val   = set(case_val)\n",
        "    case_test  = set(case_test)\n",
        "\n",
        "    # 3) Map case splits back to slice-level lists (no leakage)\n",
        "    train_slices, val_slices, test_slices = [], [], []\n",
        "    for label, items in slices_by_class.items():\n",
        "        for case_id, slice_key in items:\n",
        "            if case_id in case_train:\n",
        "                train_slices.append((case_id, slice_key))\n",
        "            elif case_id in case_val:\n",
        "                val_slices.append((case_id, slice_key))\n",
        "            elif case_id in case_test:\n",
        "                test_slices.append((case_id, slice_key))\n",
        "            else:\n",
        "                print('critical error! found case id not in train, test, or val')\n",
        "\n",
        "    return train_slices, val_slices, test_slices\n",
        "\n",
        "train_slices, val_slices, test_slices = split_by_case_stratified(slices_by_class)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FOUGt3_3UJ9U",
        "outputId": "de538301-516f-4568-fe3e-25424b982047"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "set()"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "source": [
        "# check train, test and validation set doesnt have overlapping cases\n",
        "set([slice[0] for slice in train_slices]) & set([slice[0] for slice in test_slices]) & set([slice[0] for slice in val_slices])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-vsvdHMUVlE",
        "outputId": "6ff92c84-bd5a-451d-959f-a320367e6f2b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "86"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ],
      "source": [
        "# number of cases after spliting\n",
        "len(set([slice[0] for slice in train_slices]) | set([slice[0] for slice in test_slices]) | set([slice[0] for slice in val_slices]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZMXtHxiejB5m"
      },
      "outputs": [],
      "source": [
        "train_patches = {k: patches[k] for k in train_slices}\n",
        "val_patches   = {k: patches[k] for k in val_slices}\n",
        "test_patches  = {k: patches[k] for k in test_slices}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P3y3uA0NswxC",
        "outputId": "f1da4a19-e529-4daa-8d86-8448baf84ed6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ”¹ Train Split\n",
            "Cases: 51\n",
            "Slices: 208\n",
            "Patches: 45518\n",
            "Class distribution: {1: 111, 0: 97}\n",
            "\n",
            "ðŸ”¹ Validation Split\n",
            "Cases: 17\n",
            "Slices: 74\n",
            "Patches: 16041\n",
            "Class distribution: {1: 56, 0: 18}\n",
            "\n",
            "ðŸ”¹ Test Split\n",
            "Cases: 18\n",
            "Slices: 84\n",
            "Patches: 18569\n",
            "Class distribution: {1: 71, 0: 13}\n"
          ]
        }
      ],
      "source": [
        "# Provide summarize info of number of cases, patches, class distribution and number of slices\n",
        "def summarize_split(patch_dict, label_map=None, split_name=\"\"):\n",
        "    # Count cases\n",
        "    num_cases = len(set(k[0] for k in patch_dict if isinstance(k, tuple) and len(k) > 0))\n",
        "\n",
        "    # Count total patches\n",
        "    total_patches = sum(len(paths) for paths in patch_dict.values())\n",
        "\n",
        "    # Count per class (if label map provided)\n",
        "    class_counts = Counter()\n",
        "    if label_map:\n",
        "        class_counts.update([label_map[c] for c in patch_dict.keys() if c in label_map])\n",
        "\n",
        "    # Output\n",
        "    print(f\"\\nðŸ”¹ {split_name} Split\")\n",
        "    print(f\"Cases: {num_cases}\")\n",
        "    print(f\"Slices: {len(patch_dict)}\")\n",
        "    print(f\"Patches: {total_patches}\")\n",
        "    if class_counts:\n",
        "        print(f\"Class distribution: {dict(class_counts)}\")\n",
        "\n",
        "# Run for all splits\n",
        "summarize_split(train_patches, slice_to_class, split_name=\"Train\")\n",
        "summarize_split(val_patches, slice_to_class, split_name=\"Validation\")\n",
        "summarize_split(test_patches, slice_to_class, split_name=\"Test\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hjjo8KnjUUi2"
      },
      "source": [
        "## From slice level to case level"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9NbI7jlyUTOV"
      },
      "outputs": [],
      "source": [
        "def build_case_dict(patches, slice_to_class):\n",
        "    \"\"\"\n",
        "    patches: {(case_id, slice_id): [paths,...]}  # mixed-stain lists\n",
        "    slice_to_class: {(case_id, slice_id): int}   # e.g. ('match_1')\n",
        "    returns:\n",
        "      case_dict = { case_id: { stain: [ [patches_of_slice1], [patches_of_slice2], ... ] } }\n",
        "      label_map = { case_id: int }\n",
        "    \"\"\"\n",
        "\n",
        "    # simple pattern to get stain from filename\n",
        "    stain_re = re.compile(r\"(h&e|melan|sox10)\", re.IGNORECASE)\n",
        "\n",
        "    case_dict = defaultdict(lambda: defaultdict(lambda: defaultdict(list)))  # case->stain->slice->paths\n",
        "    label_map = {}\n",
        "\n",
        "    for (case_id, slice_id), path_list in patches.items():\n",
        "        for p in path_list:\n",
        "            fname = os.path.basename(p).lower()\n",
        "            m = stain_re.search(fname)\n",
        "            if not m:\n",
        "                continue\n",
        "            stain = m.group(1).lower()\n",
        "\n",
        "            # bucket by case -> stain -> slice\n",
        "            case_dict[case_id][stain][slice_id].append(p)\n",
        "\n",
        "            # set case label once (assume consistent by leakage check)\n",
        "            lab = slice_to_class.get((case_id, slice_id))\n",
        "            if lab is not None:\n",
        "                label_map[case_id] = lab\n",
        "\n",
        "    # convert slice dicts to lists of lists (dataset expects lists)\n",
        "    case_dict_lists = {}\n",
        "    for cid, stain_dict in case_dict.items():\n",
        "        case_dict_lists[cid] = {}\n",
        "        for stain, slice_map in stain_dict.items():\n",
        "            slices = [slice_map[k] for k in sorted(slice_map.keys())]  # stable order\n",
        "            case_dict_lists[cid][stain] = slices\n",
        "\n",
        "    return case_dict_lists, label_map\n",
        "\n",
        "\n",
        "# check no data leakage\n",
        "def get_case_ids(case_dict):\n",
        "    return set(case_dict.keys())\n",
        "\n",
        "def get_all_paths(case_dict):\n",
        "    \"\"\"Flatten to a set of full file paths.\"\"\"\n",
        "    out = set()\n",
        "    for stains in case_dict.values():            # dict: stain -> list of slices\n",
        "        for slice_lists in stains.values():      # list of slices\n",
        "            for paths in slice_lists:            # each slice is a list[str]\n",
        "                out.update(paths)\n",
        "    return out\n",
        "\n",
        "def check_disjoint_sets(A, B, nameA=\"A\", nameB=\"B\"):\n",
        "    inter = A & B\n",
        "    ok = len(inter) == 0\n",
        "    return ok, inter\n",
        "\n",
        "def report_no_leak(train_case_dict, val_case_dict, test_case_dict):\n",
        "    # case-level\n",
        "    train_cases = get_case_ids(train_case_dict)\n",
        "    val_cases   = get_case_ids(val_case_dict)\n",
        "    test_cases  = get_case_ids(test_case_dict)\n",
        "\n",
        "    print(\"Cases per split:\", len(train_cases), len(val_cases), len(test_cases))\n",
        "\n",
        "    ok_tv, leak_tv = check_disjoint_sets(train_cases, val_cases, \"train\", \"val\")\n",
        "    ok_tt, leak_tt = check_disjoint_sets(train_cases, test_cases, \"train\", \"test\")\n",
        "    ok_vt, leak_vt = check_disjoint_sets(val_cases,   test_cases, \"val\",   \"test\")\n",
        "\n",
        "    # file-level\n",
        "    train_paths = get_all_paths(train_case_dict)\n",
        "    val_paths   = get_all_paths(val_case_dict)\n",
        "    test_paths  = get_all_paths(test_case_dict)\n",
        "\n",
        "    print(\"Paths per split:\", len(train_paths), len(val_paths), len(test_paths))\n",
        "\n",
        "    ok_tv_p, leak_tv_p = check_disjoint_sets(train_paths, val_paths, \"train\", \"val\")\n",
        "    ok_tt_p, leak_tt_p = check_disjoint_sets(train_paths, test_paths, \"train\", \"test\")\n",
        "    ok_vt_p, leak_vt_p = check_disjoint_sets(val_paths,   test_paths, \"val\",   \"test\")\n",
        "\n",
        "    # Summary\n",
        "    def summarise(ok, leak, label):\n",
        "        if ok:\n",
        "            print(f\"No leakage between {label}.\")\n",
        "        else:\n",
        "            print(f\"[LEAK!!!! Nooo] {label} overlap count = {len(leak)}\")\n",
        "\n",
        "    summarise(ok_tv,   leak_tv,   \"train & val (cases)\")\n",
        "    summarise(ok_tt,   leak_tt,   \"train & test (cases)\")\n",
        "    summarise(ok_vt,   leak_vt,   \"val & test (cases)\")\n",
        "    summarise(ok_tv_p, leak_tv_p, \"train & val (paths)\")\n",
        "    summarise(ok_tt_p, leak_tt_p, \"train & test (paths)\")\n",
        "    summarise(ok_vt_p, leak_vt_p, \"val & test (paths)\")\n",
        "\n",
        "def summarize_case_dict(case_dict, label_map=None, split_name=\"train\"):\n",
        "    \"\"\"\n",
        "    Returns a DataFrame with per-case counts of:\n",
        "      - total patches\n",
        "      - patches per stain\n",
        "      - number of slices per stain\n",
        "      - missing stain flags\n",
        "      - label (if label_map given)\n",
        "    \"\"\"\n",
        "    records = []\n",
        "\n",
        "    for case_id, stains in case_dict.items():\n",
        "        record = {\"case_id\": case_id, \"split\": split_name}\n",
        "        total_patches = 0\n",
        "\n",
        "        for stain in (\"h&e\", \"melan\", \"sox10\"):\n",
        "            slice_lists = stains.get(stain, [])\n",
        "            num_slices = len(slice_lists)\n",
        "            num_patches = sum(len(paths) for paths in slice_lists)\n",
        "            record[f\"{stain}_slices\"] = num_slices\n",
        "            record[f\"{stain}_patches\"] = num_patches\n",
        "            record[f\"{stain}_missing\"] = int(num_patches == 0)\n",
        "            total_patches += num_patches\n",
        "\n",
        "        record[\"total_patches\"] = total_patches\n",
        "        if label_map and case_id in label_map:\n",
        "            record[\"label\"] = label_map[case_id]\n",
        "        else:\n",
        "            record[\"label\"] = None\n",
        "\n",
        "        records.append(record)\n",
        "\n",
        "    return pd.DataFrame.from_records(records)\n",
        "\n",
        "class StainBagCaseDataset(Dataset):\n",
        "    \"\"\"\n",
        "    For each CASE returns:\n",
        "    {\n",
        "      \"case_id\": int/str,\n",
        "      \"stain_slices\": {\n",
        "          \"h&e\":   [ Tensor(P1, C, H, W), Tensor(P2, C, H, W), ... ],  # list of S_h&e slices\n",
        "          \"melan\": [ ... ],\n",
        "          \"sox10\": [ ... ],\n",
        "      },\n",
        "      \"label\": LongTensor scalar\n",
        "    }\n",
        "\n",
        "    Inputs:\n",
        "      case_dict: { case_id: { stain: [ [patches_of_slice1], [patches_of_slice2], ... ] } }\n",
        "      label_map: { case_id: int_label }\n",
        "\n",
        "    Notes:\n",
        "      - No merging across slices: each slice stays a separate bag (list element).\n",
        "      - Missing stains return an empty list [].\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        case_dict: Dict[Any, Dict[str, List[List[str]]]],\n",
        "        label_map: Dict[Any, int],\n",
        "        transform=None,\n",
        "        stains: Tuple[str, ...] = (\"h&e\", \"melan\", \"sox10\"),\n",
        "        per_slice_cap: Optional[int] = 800,        # cap patches per slice at 800\n",
        "        max_slices_per_stain: Optional[int] = None, # optional: cap #slices per stain\n",
        "        shuffle_patches: bool = True,\n",
        "        drop_empty_slices: bool = True,            # drop slices that fail to load any patch\n",
        "    ):\n",
        "\n",
        "        self.transform = transform\n",
        "        self.stains = list(stains)\n",
        "        self.per_slice_cap = per_slice_cap\n",
        "        self.max_slices_per_stain = max_slices_per_stain\n",
        "        self.shuffle_patches = shuffle_patches\n",
        "        self.drop_empty_slices = drop_empty_slices\n",
        "\n",
        "        # Flatten case_dict to an indexable list; normalize stain keys\n",
        "        self.items = []\n",
        "        for case_id, stain_map in case_dict.items():\n",
        "            if case_id not in label_map:\n",
        "                continue\n",
        "\n",
        "            norm_map = {}\n",
        "            for k, v in stain_map.items():\n",
        "                kk = k.lower()\n",
        "                norm_map[kk] = v\n",
        "\n",
        "            self.items.append((case_id, norm_map))\n",
        "\n",
        "        self.label_map = label_map\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.items)\n",
        "\n",
        "    def _load_slice_tensor(self, paths: List[str]) -> Optional[torch.Tensor]:\n",
        "        \"\"\"\n",
        "        One slice = list of patch paths -> Tensor(P, C, H, W).\n",
        "        Applies transform; shuffles & caps per-slice; skips unreadable images.\n",
        "        \"\"\"\n",
        "        patch_paths = list(paths)\n",
        "        if self.shuffle_patches:\n",
        "            random.shuffle(patch_paths)\n",
        "\n",
        "        if self.per_slice_cap and len(patch_paths) > self.per_slice_cap:\n",
        "            patch_paths = patch_paths[:self.per_slice_cap]\n",
        "\n",
        "        imgs = []\n",
        "        for p in patch_paths:\n",
        "            try:\n",
        "                img = Image.open(p).convert(\"RGB\")\n",
        "                if self.transform:\n",
        "                    img = self.transform(img)\n",
        "                imgs.append(img)\n",
        "            except Exception:\n",
        "                # unreadable\n",
        "                continue\n",
        "\n",
        "        if len(imgs) == 0:\n",
        "            return None\n",
        "        return torch.stack(imgs)  # (P, C, H, W)\n",
        "\n",
        "    def __getitem__(self, idx: int) -> Dict[str, Any]:\n",
        "        case_id, stain_map = self.items[idx]\n",
        "        label = torch.tensor(self.label_map[case_id], dtype=torch.long)\n",
        "\n",
        "        stain_slices: Dict[str, List[torch.Tensor]] = {}\n",
        "        for stain in self.stains:\n",
        "            # Get list of slices (each slice is list[str] of patch paths)\n",
        "            slice_lists = stain_map.get(stain, []) or []\n",
        "\n",
        "            # Optionally cap the number of slices per stain\n",
        "            if self.max_slices_per_stain is not None and len(slice_lists) > self.max_slices_per_stain:\n",
        "                # deterministic crop\n",
        "                slice_lists = slice_lists[:self.max_slices_per_stain]\n",
        "\n",
        "            tensors_for_stain: List[torch.Tensor] = []\n",
        "            for sl in slice_lists:\n",
        "                if not sl:\n",
        "                    continue\n",
        "                sl_tensor = self._load_slice_tensor(sl)\n",
        "                if sl_tensor is None:\n",
        "                    if self.drop_empty_slices:\n",
        "                        continue\n",
        "                    else:\n",
        "                        # Represent empty as zero-length tensor??\n",
        "                        continue\n",
        "                tensors_for_stain.append(sl_tensor)\n",
        "\n",
        "            stain_slices[stain] = tensors_for_stain\n",
        "\n",
        "        return {\n",
        "            \"case_id\": case_id,\n",
        "            \"stain_slices\": stain_slices,  # dict[stain] -> list[Tensor(P,C,H,W)]\n",
        "            \"label\": label,\n",
        "        }\n",
        "\n",
        "\n",
        "def case_collate_fn(batch):\n",
        "    \"\"\"\n",
        "    Keep variable-length structures; model.forward expects List[case_dict].\n",
        "    Use batch_size=1 to avoid padding/masking.\n",
        "    \"\"\"\n",
        "    return batch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ox-hYcYQYZlk",
        "outputId": "8323d31a-0061-4486-8352-5560137a27a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cases per split: 51 17 18\n",
            "Paths per split: 45518 16041 18569\n",
            "No leakage between train & val (cases).\n",
            "No leakage between train & test (cases).\n",
            "No leakage between val & test (cases).\n",
            "No leakage between train & val (paths).\n",
            "No leakage between train & test (paths).\n",
            "No leakage between val & test (paths).\n",
            "\n",
            "Label distribution per split:\n",
            "label   0   1\n",
            "split        \n",
            "test    6  12\n",
            "train  17  34\n",
            "val     5  12\n",
            "\n",
            "Mean patches per stain per split:\n",
            "       h&e_patches  melan_patches  sox10_patches\n",
            "split                                           \n",
            "test         444.1          293.8          293.8\n",
            "train        468.9          235.7          187.9\n",
            "val          460.7          275.2          207.7\n",
            "\n",
            "Median patches per stain per split:\n",
            "       h&e_patches  melan_patches  sox10_patches\n",
            "split                                           \n",
            "test         283.0          222.5          242.0\n",
            "train        323.0          182.0          165.0\n",
            "val          429.0          172.0          124.0\n",
            "\n",
            "Missing stain proportion:\n",
            "       h&e_missing  melan_missing  sox10_missing\n",
            "split                                           \n",
            "test           0.0          0.056          0.000\n",
            "train          0.0          0.039          0.020\n",
            "val            0.0          0.000          0.059\n",
            "DataLoader created successfully!\n"
          ]
        }
      ],
      "source": [
        "train_case_dict, train_label_map = build_case_dict(train_patches, slice_to_class)\n",
        "val_case_dict,   val_label_map   = build_case_dict(val_patches, slice_to_class)\n",
        "test_case_dict,  test_label_map  = build_case_dict(test_patches, slice_to_class)\n",
        "\n",
        "report_no_leak(train_case_dict, val_case_dict, test_case_dict)\n",
        "\n",
        "# Build the tables for each split\n",
        "train_df = summarize_case_dict(train_case_dict, train_label_map, \"train\")\n",
        "val_df   = summarize_case_dict(val_case_dict,   val_label_map,   \"val\")\n",
        "test_df  = summarize_case_dict(test_case_dict,  test_label_map,  \"test\")\n",
        "\n",
        "# Combine\n",
        "all_df = pd.concat([train_df, val_df, test_df], ignore_index=True)\n",
        "\n",
        "print(\"\\nLabel distribution per split:\")\n",
        "print(all_df.groupby([\"split\", \"label\"])[\"case_id\"].nunique().unstack(fill_value=0))\n",
        "\n",
        "stain_patch_cols = [\"h&e_patches\", \"melan_patches\", \"sox10_patches\"]\n",
        "print(\"\\nMean patches per stain per split:\")\n",
        "print(all_df.groupby(\"split\")[stain_patch_cols].mean().round(1))\n",
        "\n",
        "print(\"\\nMedian patches per stain per split:\")\n",
        "print(all_df.groupby(\"split\")[stain_patch_cols].median().round(1))\n",
        "\n",
        "missing_cols = [\"h&e_missing\", \"melan_missing\", \"sox10_missing\"]\n",
        "print(\"\\nMissing stain proportion:\")\n",
        "print((all_df.groupby(\"split\")[missing_cols].mean()).round(3))\n",
        "\n",
        "train_ds = StainBagCaseDataset(\n",
        "    train_case_dict, train_label_map,\n",
        "    transform=train_transform,\n",
        "    shuffle_patches=True,\n",
        ")\n",
        "\n",
        "val_ds = StainBagCaseDataset(\n",
        "    val_case_dict, val_label_map,\n",
        "    transform=transform,\n",
        "    shuffle_patches=False, # determinism for eval\n",
        ")\n",
        "\n",
        "test_ds = StainBagCaseDataset(\n",
        "    test_case_dict, test_label_map,\n",
        "    transform=transform,\n",
        "    shuffle_patches=False,\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_ds, batch_size=1, shuffle=True,\n",
        "    num_workers=2, pin_memory=True, collate_fn=case_collate_fn\n",
        ")\n",
        "val_loader = DataLoader(\n",
        "    val_ds, batch_size=1, shuffle=False,\n",
        "    num_workers=2, pin_memory=True, collate_fn=case_collate_fn\n",
        ")\n",
        "test_loader = DataLoader(\n",
        "    test_ds, batch_size=1, shuffle=False,\n",
        "    num_workers=2, pin_memory=True, collate_fn=case_collate_fn\n",
        ")\n",
        "\n",
        "print('DataLoader created successfully!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zODWvmfjFf2I"
      },
      "outputs": [],
      "source": [
        "\n",
        "# # get one case from the train loader\n",
        "# sample_batch = next(iter(train_loader))\n",
        "# sample = sample_batch[0]\n",
        "\n",
        "# print(f\"Case ID: {sample['case_id']}\")\n",
        "# print(f\"Label: {sample['label'].item()}\")\n",
        "\n",
        "# for stain, slices in sample[\"stain_slices\"].items():\n",
        "#     if not slices:  # empty list (no slices for this stain)\n",
        "#         print(f\"{stain}: missing\")\n",
        "#         continue\n",
        "\n",
        "#     # quick summary per stain\n",
        "#     n_slices = len(slices)\n",
        "#     n_patches_total = sum(sl.shape[0] for sl in slices)\n",
        "#     shapes = [tuple(sl.shape) for sl in slices[:3]]  # show up to 3 slice shapes\n",
        "\n",
        "#     print(f\"{stain}: {n_slices} slices | {n_patches_total} patches total\")\n",
        "#     print(f\"  example slice shapes: {shapes}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8LsCk9rs5stB"
      },
      "outputs": [],
      "source": [
        "# this pools the patch level features into single bag level representation for MIL\n",
        "class AttentionPool(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim=128):\n",
        "      #input_dim: the dimensionality of each input feature vector (e.g., 512 if youâ€™re using a CNN encoder like ResNet).\n",
        "      #hidden_dim: the size of the hidden layer used inside the attention mechanism (default = 128).\n",
        "      #This defines how much capacity the attention sub-network has to learn complex relationships.\n",
        "        super().__init__()\n",
        "        # creates small neural network to compute attention scores for each patch\n",
        "        # each patch embedding is passed through a linear layer, tanh for nonlinearity, and another linear layer to get a scalar score\n",
        "        self.attention = nn.Sequential(\n",
        "            nn.Linear(input_dim, hidden_dim),\n",
        "            nn.Tanh(), #non-linear layer with vals -1 and 1\n",
        "            nn.Linear(hidden_dim, 1) # linear layer that gives scalar\n",
        "        )\n",
        "    def forward(self, x, return_weights=False):\n",
        "        # x is of shape (B, M, D) where B is batch size or number of cases,\n",
        "        # M is number of patches per bag, and D is the embedding dimensions for each patch\n",
        "        weights = self.attention(x)     # (B, M, 1)\n",
        "        weights = torch.softmax(weights, dim=1) # softmax so that weights are positive\n",
        "        # outputs attention scores for each patch and normalized with softmax\n",
        "        # D is the embedding dimension which is size of feature vector for each patch after going through the patch classifier\n",
        "        weighted_x = (weights * x).sum(dim=1)  # (B, D) # multiplying the weights by z (z is the tensor of shape B, D)\n",
        "        # returning the raw attention weights per patch just to help with visualization of the weights for each patch\n",
        "        if return_weights:\n",
        "            return weighted_x, weights.squeeze(-1)  # (B, D), (B, M) # D is a 1D vector of the low-level embedding\n",
        "        return weighted_x # use these weights to visualize which patches have high attention\n",
        "        # B =1 means 1 slice per batch, each patch has a weight, so there are M weights (M is # of patches per batch)\n",
        "        # they took B as 1 as last quarter\n",
        "        # B = 1 slice with M patches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VtHulqvBWenX"
      },
      "outputs": [],
      "source": [
        "class HierarchicalAttnMIL(nn.Module):\n",
        "    def __init__(self, base_model, num_classes=2, embed_dim=512):\n",
        "        super().__init__()\n",
        "\n",
        "        # Shared feature extractor (pretrained CNN)\n",
        "        self.features = base_model.features\n",
        "\n",
        "        # Adaptive pooling to get richer features than just 1x1\n",
        "        self.pool = nn.AdaptiveAvgPool2d((2, 2))\n",
        "\n",
        "        # Patch projector: maps CNN features to patch embeddings\n",
        "        self.patch_projector = nn.Linear(base_model.classifier.in_features * 4, embed_dim)\n",
        "\n",
        "        # First level: Patch-level attention (within each stain-slice)\n",
        "        self.patch_attention = AttentionPool(embed_dim)\n",
        "\n",
        "        # Second level: Stain-level attention (across slices within each stain)\n",
        "        self.stain_attention = AttentionPool(embed_dim)\n",
        "\n",
        "        # Third level: Case-level attention (across different stains)\n",
        "        self.case_attention = AttentionPool(embed_dim)\n",
        "\n",
        "        # Final classifier\n",
        "        self.classifier = nn.Linear(embed_dim, num_classes)\n",
        "\n",
        "    def forward(self, stain_slices_dict, return_attn_weights=False):\n",
        "        \"\"\"\n",
        "        Input: stain_slices_dict = {\n",
        "            \"h&e\": [slice1_tensor, slice2_tensor, ...],   # each slice: (P, C, H, W)\n",
        "            \"melan\": [slice1_tensor, slice2_tensor, ...],\n",
        "            \"sox10\": [slice1_tensor, slice2_tensor, ...]\n",
        "        }\n",
        "        \"\"\"\n",
        "\n",
        "        stain_embeddings = {}\n",
        "        stain_attention_weights = {}\n",
        "\n",
        "        # Process each stain type separately\n",
        "        for stain_name, slice_list in stain_slices_dict.items():\n",
        "            if not slice_list:  # Skip if no slices for this stain\n",
        "                continue\n",
        "\n",
        "            slice_embeddings = []\n",
        "            slice_attention_weights = []\n",
        "\n",
        "            # Process each slice within this stain\n",
        "            for slice_tensor in slice_list:\n",
        "                # slice_tensor shape: (P, C, H, W) where P = number of patches\n",
        "                P, C, H, W = slice_tensor.shape\n",
        "\n",
        "                # Extract features for all patches in this slice\n",
        "                patch_features = self.features(slice_tensor)  # (P, F, h, w)\n",
        "                pooled = self.pool(patch_features).view(P, -1)  # (P, 4*F)\n",
        "                patch_embeddings = self.patch_projector(pooled)  # (P, D)\n",
        "\n",
        "                # Apply patch-level attention to get slice embedding\n",
        "                if return_attn_weights:\n",
        "                    slice_emb, patch_weights = self.patch_attention(\n",
        "                        patch_embeddings.unsqueeze(0), return_weights=True\n",
        "                    )\n",
        "                    slice_attention_weights.append(patch_weights.squeeze(0))\n",
        "                else:\n",
        "                    slice_emb = self.patch_attention(patch_embeddings.unsqueeze(0))\n",
        "\n",
        "                slice_embeddings.append(slice_emb.squeeze(0))  # (D,) (D is 512 in our case!)\n",
        "\n",
        "            # Stack slice embeddings for this stain\n",
        "            if slice_embeddings:\n",
        "                stain_slice_embeddings = torch.stack(slice_embeddings)  # (num_slices, D)\n",
        "\n",
        "                # Apply stain-level attention across slices\n",
        "                if return_attn_weights:\n",
        "                    stain_emb, stain_weights = self.stain_attention(\n",
        "                        stain_slice_embeddings.unsqueeze(0), return_weights=True\n",
        "                    )\n",
        "                    stain_attention_weights[stain_name] = {\n",
        "                        'slice_weights': stain_weights.squeeze(0),\n",
        "                        'patch_weights': slice_attention_weights\n",
        "                    }\n",
        "                else:\n",
        "                    stain_emb = self.stain_attention(stain_slice_embeddings.unsqueeze(0))\n",
        "\n",
        "                stain_embeddings[stain_name] = stain_emb.squeeze(0)  # (D,)\n",
        "\n",
        "        # If no stains have data, return zero logits\n",
        "        if not stain_embeddings:\n",
        "            logits = torch.zeros(1, self.classifier.out_features).to(next(self.parameters()).device)\n",
        "            if return_attn_weights:\n",
        "                return logits, {}\n",
        "            return logits\n",
        "\n",
        "        # Stack stain embeddings for case-level attention (fusion point)\n",
        "        stain_emb_list = list(stain_embeddings.values())\n",
        "        case_stain_embeddings = torch.stack(stain_emb_list)  # (num_stains, D)\n",
        "\n",
        "        # Apply case-level attention across stains\n",
        "        if return_attn_weights:\n",
        "            case_emb, case_weights = self.case_attention(\n",
        "                case_stain_embeddings.unsqueeze(0), return_weights=True\n",
        "            )\n",
        "            # Package all attention weights for return -- can use this for identifying important cases / stains / slices !\n",
        "            all_weights = {\n",
        "                'case_weights': case_weights.squeeze(0),\n",
        "                'stain_weights': stain_attention_weights,\n",
        "                'stain_order': list(stain_embeddings.keys())\n",
        "            }\n",
        "        else:\n",
        "            case_emb = self.case_attention(case_stain_embeddings.unsqueeze(0))\n",
        "\n",
        "        # Final classification\n",
        "        logits = self.classifier(case_emb)  # (1, num_classes)\n",
        "\n",
        "        if return_attn_weights:\n",
        "            return logits.squeeze(0), all_weights\n",
        "\n",
        "        # Old model expected batched input. New model works with one case at a time (batch_size=1 in your data loader), so return single prediction\n",
        "        return logits.squeeze(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JrXxnvADF8HS"
      },
      "source": [
        "## hannah's code below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AeQmu9nRGBT0",
        "outputId": "9d5e9cf8-0016-45c0-c054-8585e6cecbae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ§¬ Patch count by class for Train:\n",
            "  Benign (0):     18125 patches\n",
            "  High-grade (1): 27393 patches\n",
            "\n",
            "ðŸ§¬ Patch count by class for Validation:\n",
            "  Benign (0):     3568 patches\n",
            "  High-grade (1): 12473 patches\n",
            "\n",
            "ðŸ§¬ Patch count by class for Test:\n",
            "  Benign (0):     4113 patches\n",
            "  High-grade (1): 14456 patches\n"
          ]
        }
      ],
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "def count_patches_by_class(patch_dict, case_to_class, split_name):\n",
        "    class_patch_counts = defaultdict(int)\n",
        "\n",
        "    for case, patches in patch_dict.items():\n",
        "        label = case_to_class[case]\n",
        "        class_patch_counts[label] += len(patches)\n",
        "\n",
        "    print(f\"\\nðŸ§¬ Patch count by class for {split_name}:\")\n",
        "    print(f\"  Benign (0):     {class_patch_counts[0]} patches\")\n",
        "    print(f\"  High-grade (1): {class_patch_counts[1]} patches\")\n",
        "\n",
        "    return class_patch_counts\n",
        "\n",
        "# Count patches per class for each split\n",
        "train_counts = count_patches_by_class(train_patches, slice_to_class, \"Train\")\n",
        "val_counts   = count_patches_by_class(val_patches, slice_to_class, \"Validation\")\n",
        "test_counts  = count_patches_by_class(test_patches, slice_to_class, \"Test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c7SXpMFEGH6_"
      },
      "outputs": [],
      "source": [
        "# def save_checkpoint_to_drive(model, arch, optimizer, epoch, drive_folder=\"MyDrive/Checkpoints\"):\n",
        "#     checkpoint_dir = os.path.join(\"/content/drive\", drive_folder)\n",
        "#     os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "\n",
        "#     timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "#     filename = f\"{checkpoint_dir}/{timestamp}_{arch}_epoch{epoch}.pth\"\n",
        "\n",
        "#     checkpoint = {\n",
        "#         \"arch\": arch,\n",
        "#         \"model_state_dict\": model.state_dict(),\n",
        "#         \"epoch\": epoch,\n",
        "#         \"optimizer_state_dict\": optimizer.state_dict(),\n",
        "#     }\n",
        "\n",
        "#     torch.save(checkpoint, filename)\n",
        "#     print(f\"âœ… Checkpoint saved to Google Drive: {filename}\")\n",
        "\n",
        "# def validation(model, criterion, val_loader):\n",
        "#     val_loss = 0\n",
        "#     correct_total = 0\n",
        "#     sample_total = 0\n",
        "#     model.eval()\n",
        "#     with torch.no_grad():\n",
        "#         for bags, labels in val_loader:\n",
        "#             bags = bags.to(device)\n",
        "#             labels = labels.to(device)\n",
        "#             outputs = model(bags)\n",
        "#             loss = criterion(outputs, labels)\n",
        "#             val_loss += loss.item() * labels.size(0)\n",
        "#             preds = torch.argmax(outputs, dim=1)\n",
        "#             correct_total += (preds == labels).sum().item()\n",
        "#             sample_total += labels.size(0)\n",
        "#     return val_loss / sample_total, correct_total / sample_total\n",
        "\n",
        "# # def train_model(model, optimizer, criterion, train_loader, val_loader, arch, checkpoint_dir, epochs=5):\n",
        "# def train_model(model, optimizer, criterion, train_loader, val_loader, arch, epochs=5, start_epoch=0):\n",
        "#     for epoch in range(start_epoch, epochs):\n",
        "#         model.train()\n",
        "#         running_loss = 0\n",
        "#         for bags, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
        "#             bags = bags.to(device)\n",
        "#             labels = labels.to(device)\n",
        "#             optimizer.zero_grad()\n",
        "#             outputs = model(bags)\n",
        "#             loss = criterion(outputs, labels)\n",
        "#             loss.backward()\n",
        "#             optimizer.step()\n",
        "#             running_loss += loss.item()\n",
        "#         val_loss, val_acc = validation(model, criterion, val_loader)\n",
        "#         print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {running_loss/len(train_loader):.3f}, Val Loss: {val_loss:.3f}, Val Acc: {val_acc:.3f}\")\n",
        "#         save_checkpoint_to_drive(model, arch, optimizer, epoch+1, drive_folder=\"MyDrive/Checkpoints\")\n",
        "#     return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IBW4mUq5fNAa"
      },
      "outputs": [],
      "source": [
        "def save_checkpoint_to_drive(model, arch, optimizer, epoch, drive_folder=\"MyDrive/Checkpoints\"):\n",
        "    checkpoint_dir = os.path.join(\"/content/drive\", drive_folder)\n",
        "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    filename = f\"{checkpoint_dir}/{timestamp}_{arch}_epoch{epoch}.pth\"\n",
        "\n",
        "    checkpoint = {\n",
        "        \"arch\": arch,\n",
        "        \"model_state_dict\": model.state_dict(),\n",
        "        \"epoch\": epoch,\n",
        "        \"optimizer_state_dict\": optimizer.state_dict(),\n",
        "    }\n",
        "\n",
        "    torch.save(checkpoint, filename)\n",
        "    print(f\"âœ… Checkpoint saved to Google Drive: {filename}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EtaPij_E-VY9"
      },
      "outputs": [],
      "source": [
        "# function adds Complete training loop with progress bars using tqdm\n",
        "\n",
        "# Validation function to monitor performance during training\n",
        "\n",
        "# Proper tensor shape handling - dealing with batch dimensions since you're using batch_size=1\n",
        "\n",
        "# Loss calculation and backpropagation\n",
        "\n",
        "# Accuracy tracking\n",
        "\n",
        "def train_model(model, optimizer, criterion, train_loader, val_loader, arch, epochs=5, start_epoch=0):\n",
        "    model.train()\n",
        "\n",
        "    for epoch in range(start_epoch, epochs):\n",
        "        running_loss = 0.0\n",
        "\n",
        "        for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
        "            case_data = batch[0]  # Get the first (and only) case in the batch\n",
        "\n",
        "            stain_slices = case_data[\"stain_slices\"]\n",
        "            label = case_data[\"label\"].to(device)\n",
        "\n",
        "            # Forward pass - model outputs [2] (logits for 2 classes)\n",
        "            outputs = model(stain_slices)\n",
        "\n",
        "            # Add batch dimension: [2] -> [1, 2]\n",
        "            outputs = outputs.unsqueeze(0)\n",
        "\n",
        "            # Ensure label has batch dimension: scalar -> [1]\n",
        "            if label.dim() == 0:\n",
        "                label = label.unsqueeze(0)\n",
        "\n",
        "            # Now shapes are:\n",
        "            # outputs: [1, 2] (batch_size=1, num_classes=2)\n",
        "            # label: [1] (batch_size=1)\n",
        "            # This is exactly what CrossEntropyLoss expects!\n",
        "\n",
        "            loss = criterion(outputs, label)\n",
        "\n",
        "            # Backward pass\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        # Validation\n",
        "        val_loss, val_acc = validation(model, criterion, val_loader)\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, \"\n",
        "              f\"Train Loss: {running_loss/len(train_loader):.3f}, \"\n",
        "              f\"Val Loss: {val_loss:.3f}, Val Acc: {val_acc:.3f}\")\n",
        "        save_checkpoint_to_drive(model, arch, optimizer, epoch+1, drive_folder=\"MyDrive/Checkpoints\")\n",
        "    return model\n",
        "\n",
        "def validation(model, criterion, val_loader):\n",
        "    val_loss = 0\n",
        "    correct_total = 0\n",
        "    sample_total = 0\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            case_data = batch[0]\n",
        "            stain_slices = case_data[\"stain_slices\"]\n",
        "            label = case_data[\"label\"].to(device)\n",
        "\n",
        "            outputs = model(stain_slices)\n",
        "\n",
        "            # Add batch dimension for loss calculation\n",
        "            outputs = outputs.unsqueeze(0)  # [1, 2]\n",
        "            if label.dim() == 0:\n",
        "                label = label.unsqueeze(0)  # [1]\n",
        "\n",
        "            loss = criterion(outputs, label)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            # Calculate accuracy\n",
        "            pred = torch.argmax(outputs, dim=1)  # [1]\n",
        "            correct_total += (pred == label).sum().item()\n",
        "            sample_total += 1\n",
        "\n",
        "    model.train()\n",
        "    return val_loss / max(sample_total, 1), correct_total / max(sample_total, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWZp9d6sGIw5",
        "outputId": "4d11f25e-630b-413f-f3ac-b03a186bd435"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PatchClassifier(\n",
              "  (features): Sequential(\n",
              "    (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "    (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu0): ReLU(inplace=True)\n",
              "    (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "    (denseblock1): _DenseBlock(\n",
              "      (denselayer1): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer2): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer3): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer4): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer5): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer6): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (transition1): _Transition(\n",
              "      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "    )\n",
              "    (denseblock2): _DenseBlock(\n",
              "      (denselayer1): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer2): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer3): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer4): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer5): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer6): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer7): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer8): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer9): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer10): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer11): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer12): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (transition2): _Transition(\n",
              "      (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "    )\n",
              "    (denseblock3): _DenseBlock(\n",
              "      (denselayer1): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer2): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer3): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer4): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer5): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer6): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer7): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer8): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer9): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer10): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer11): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer12): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer13): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer14): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer15): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer16): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer17): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer18): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer19): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer20): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer21): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer22): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer23): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer24): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (transition3): _Transition(\n",
              "      (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "    )\n",
              "    (denseblock4): _DenseBlock(\n",
              "      (denselayer1): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer2): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer3): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer4): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer5): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer6): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer7): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer8): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer9): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer10): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer11): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer12): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer13): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer14): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer15): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer16): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (norm5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (pool): AdaptiveAvgPool2d(output_size=(2, 2))\n",
              "  (classifier): Linear(in_features=4096, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ],
      "source": [
        "# ------------------- Load pretrained patch model -------------------\n",
        "# used for classifiing individual image patches, its convolutional layers are used as frozen feature extractor in MIL\n",
        "class PatchClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        base = models.densenet121(weights=models.DenseNet121_Weights.DEFAULT)\n",
        "        # loading the pre trained densenet model\n",
        "        self.features = base.features\n",
        "        # compress final convolutional output of each image to 2x2 feature map\n",
        "        self.pool = nn.AdaptiveAvgPool2d((2,2))\n",
        "        self.classifier = nn.Linear(base.classifier.in_features * 4, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # first passes input images through Densenet convolutional layers to get feature maps\n",
        "        x = self.features(x)\n",
        "        # applies pooling\n",
        "        x = self.pool(x).view(x.size(0), -1)\n",
        "        # passes to final classifier layer to get the logits\n",
        "        return self.classifier(x)\n",
        "\n",
        "patch_model = PatchClassifier()\n",
        "# patch_model.load_state_dict(torch.load(os.path.join(filtered_patches_dir, \"patch_classifier.pth\")))\n",
        "patch_model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dMwYAbgEInNZ"
      },
      "outputs": [],
      "source": [
        "# Initialize the model with the new architecture\n",
        "\n",
        "# Initialize the model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Create base model (same as before)\n",
        "base_model = models.densenet121(weights=None)\n",
        "base_model.features = patch_model.features  # Use pretrained features\n",
        "\n",
        "# Create hierarchical attention MIL model\n",
        "model = HierarchicalAttnMIL(base_model=base_model).to(device)\n",
        "\n",
        "# Freeze the feature extractor -- Freezes the CNN feature extractor (DenseNet layers) since we only trains the attention mechanisms and classifier\n",
        "for param in model.features.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Optimizer and loss\n",
        "optimizer = torch.optim.Adam([\n",
        "    {'params': model.patch_projector.parameters()},\n",
        "    {'params': model.patch_attention.parameters()},\n",
        "    {'params': model.stain_attention.parameters()},\n",
        "    {'params': model.case_attention.parameters()},\n",
        "    {'params': model.classifier.parameters()}\n",
        "], lr=0.001)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "arch = \"densenet121_hierarchical_mil\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "73xdaZWiyAtk"
      },
      "outputs": [],
      "source": [
        "# check if we need to load from checkpoint before training\n",
        "checkpoint_dir = \"/content/drive/MyDrive/Checkpoints\"\n",
        "checkpoint_pattern = re.compile(r'epoch(\\d+)\\.pth')\n",
        "start_epoch = 0\n",
        "checkpoint_path = None\n",
        "checkpoint_files = [f for f in os.listdir(checkpoint_dir) if f.endswith('.pth')]\n",
        "\n",
        "def load_latest_checkpoint(checkpoint_dir, model, optimizer, device):\n",
        "    # Find all files in the directory\n",
        "    checkpoint_files = [f for f in os.listdir(checkpoint_dir) if checkpoint_pattern.search(f)]\n",
        "    if len(checkpoint_files)>=1:\n",
        "        # Sort by extracted epoch number\n",
        "        checkpoint_files.sort(\n",
        "            key=lambda x: int(checkpoint_pattern.search(x).group(1)) if checkpoint_pattern.search(x) else -1)\n",
        "        # Get the path of the latest checkpoint (last one in the sorted list)\n",
        "        checkpoint_path = os.path.join(checkpoint_dir, checkpoint_files[-1])\n",
        "        print(f\"Latest checkpoint in directory is **{checkpoint_path}**\")\n",
        "\n",
        "        checkpoint = torch.load(checkpoint_path, map_location=device)\n",
        "        model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "        start_epoch = checkpoint['epoch']\n",
        "        return model, optimizer, start_epoch\n",
        "    return model, optimizer, 0\n",
        "\n",
        "model, optimizer, start_epoch = load_latest_checkpoint(checkpoint_dir, model, optimizer, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "D8-VduK5I07K",
        "outputId": "8e16d7be-7476-4b2d-b0ad-7d10157ae4b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/5:   0%|          | 0/51 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "Epoch 1/5:   2%|â–         | 1/51 [17:36<14:40:04, 1056.09s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2113421901.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0march\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-3804011833.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, optimizer, criterion, train_loader, val_loader, arch, epochs, start_epoch)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0;31m# Forward pass - model outputs [2] (logits for 2 classes)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstain_slices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0;31m# Add batch dimension: [2] -> [1, 2]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-434578012.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, stain_slices_dict, return_attn_weights)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m                 \u001b[0;31m# Extract features for all patches in this slice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mpatch_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslice_tensor\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (P, F, h, w)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m                 \u001b[0mpooled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatch_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (P, 4*F)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m                 \u001b[0mpatch_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch_projector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpooled\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (P, D)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchvision/models/densenet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, init_features)\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0minit_features\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0mnew_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m             \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchvision/models/densenet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0mbottleneck_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprev_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         \u001b[0mnew_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbottleneck_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_rate\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0mnew_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 548\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    541\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m             )\n\u001b[0;32m--> 543\u001b[0;31m         return F.conv2d(\n\u001b[0m\u001b[1;32m    544\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m         )\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "train_model(model, optimizer, criterion, train_loader, val_loader, arch, epochs=5, start_epoch=start_epoch)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# mini dateset to check for errors prior to the training period -- not actually used for training / testing :)\n",
        "\n",
        "# Create a minimal training set with just 2-3 cases\n",
        "def create_mini_dataset(full_case_dict, full_label_map, num_cases=3):\n",
        "    \"\"\"Create a tiny dataset for debugging\"\"\"\n",
        "    case_ids = list(full_case_dict.keys())[:num_cases]\n",
        "    mini_case_dict = {cid: full_case_dict[cid] for cid in case_ids}\n",
        "    mini_label_map = {cid: full_label_map[cid] for cid in case_ids}\n",
        "    return mini_case_dict, mini_label_map\n",
        "\n",
        "# Create mini datasets\n",
        "mini_train_case_dict, mini_train_label_map = create_mini_dataset(train_case_dict, train_label_map, num_cases=2)\n",
        "mini_val_case_dict, mini_val_label_map = create_mini_dataset(val_case_dict, val_label_map, num_cases=1)\n",
        "\n",
        "print(f\"Mini train set: {len(mini_train_case_dict)} cases\")\n",
        "print(f\"Mini val set: {len(mini_val_case_dict)} cases\")\n",
        "\n",
        "# Create mini dataloaders\n",
        "mini_train_ds = StainBagCaseDataset(\n",
        "    mini_train_case_dict, mini_train_label_map,\n",
        "    transform=train_transform,\n",
        "    shuffle_patches=True,\n",
        "    per_slice_cap=50,  # Limit patches per slice for speed\n",
        "    max_slices_per_stain=2  # Limit slices per stain\n",
        ")\n",
        "\n",
        "mini_val_ds = StainBagCaseDataset(\n",
        "    mini_val_case_dict, mini_val_label_map,\n",
        "    transform=transform,\n",
        "    shuffle_patches=False,\n",
        "    per_slice_cap=50,\n",
        "    max_slices_per_stain=2\n",
        ")\n",
        "\n",
        "mini_train_loader = DataLoader(\n",
        "    mini_train_ds, batch_size=1, shuffle=True,\n",
        "    num_workers=0,  # Set to 0 for debugging to avoid multiprocessing issues\n",
        "    pin_memory=False,\n",
        "    collate_fn=case_collate_fn\n",
        ")\n",
        "\n",
        "mini_val_loader = DataLoader(\n",
        "    mini_val_ds, batch_size=1, shuffle=False,\n",
        "    num_workers=0,\n",
        "    pin_memory=False,\n",
        "    collate_fn=case_collate_fn\n",
        ")\n",
        "\n",
        "def quick_debug_training(model, optimizer, criterion, train_loader):\n",
        "    \"\"\"Run just one batch to see if everything works\"\"\"\n",
        "    model.train()\n",
        "\n",
        "    # Get just one batch\n",
        "    batch = next(iter(train_loader))\n",
        "    case_data = batch[0]\n",
        "\n",
        "    print(\"=== DEBUGGING SINGLE BATCH ===\")\n",
        "    print(f\"Case ID: {case_data['case_id']}\")\n",
        "    print(f\"Label: {case_data['label']}\")\n",
        "\n",
        "    # Check stain slices structure\n",
        "    for stain, slices in case_data[\"stain_slices\"].items():\n",
        "        print(f\"{stain}: {len(slices)} slices\")\n",
        "        for i, slice_tensor in enumerate(slices):\n",
        "            print(f\"  Slice {i}: {slice_tensor.shape}\")\n",
        "\n",
        "    # Move to device\n",
        "    stain_slices = case_data[\"stain_slices\"]\n",
        "    label = case_data[\"label\"].to(device)\n",
        "\n",
        "    # Forward pass\n",
        "    print(\"\\n=== FORWARD PASS ===\")\n",
        "    try:\n",
        "        outputs = model(stain_slices)\n",
        "        print(f\"Outputs: {outputs}\")\n",
        "        print(f\"Output shape: {outputs.shape}\")\n",
        "\n",
        "        # âœ… FIX: Add batch dimension for CrossEntropyLoss\n",
        "        # outputs should be [batch_size, num_classes] = [1, 2]\n",
        "        # label should be [batch_size] = [1]\n",
        "        outputs_batch = outputs.unsqueeze(0)  # [2] -> [1, 2]\n",
        "        label_batch = label.unsqueeze(0)      # scalar -> [1]\n",
        "\n",
        "        print(f\"Shapes for loss calculation:\")\n",
        "        print(f\"  Outputs: {outputs_batch.shape}\")\n",
        "        print(f\"  Label: {label_batch.shape}\")\n",
        "\n",
        "        loss = criterion(outputs_batch, label_batch)\n",
        "        print(f\"Loss: {loss.item()}\")\n",
        "\n",
        "        # Backward pass\n",
        "        print(\"\\n=== BACKWARD PASS ===\")\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        print(\"âœ… SUCCESS: Forward and backward pass completed!\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ ERROR: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "\n",
        "# Run the quick debug\n",
        "quick_debug_training(model, optimizer, criterion, mini_train_loader)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJqjfPAZYVPl",
        "outputId": "a23451f7-4dad-437d-c411-480c20deb599"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mini train set: 2 cases\n",
            "Mini val set: 1 cases\n",
            "=== DEBUGGING SINGLE BATCH ===\n",
            "Case ID: 89\n",
            "Label: 1\n",
            "h&e: 2 slices\n",
            "  Slice 0: torch.Size([50, 3, 224, 224])\n",
            "  Slice 1: torch.Size([50, 3, 224, 224])\n",
            "melan: 1 slices\n",
            "  Slice 0: torch.Size([50, 3, 224, 224])\n",
            "sox10: 1 slices\n",
            "  Slice 0: torch.Size([50, 3, 224, 224])\n",
            "\n",
            "=== FORWARD PASS ===\n",
            "Outputs: tensor([-0.1371,  0.1461], grad_fn=<SqueezeBackward1>)\n",
            "Output shape: torch.Size([2])\n",
            "Shapes for loss calculation:\n",
            "  Outputs: torch.Size([1, 2])\n",
            "  Label: torch.Size([1])\n",
            "Loss: 0.5615600943565369\n",
            "\n",
            "=== BACKWARD PASS ===\n",
            "âœ… SUCCESS: Forward and backward pass completed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LEenxX84ycey"
      },
      "outputs": [],
      "source": [
        "# ------------ model evaluation ---------------------\n",
        "model.eval()\n",
        "all_preds, all_trues = [], []\n",
        "all_patch_preds, all_patch_trues = [], []\n",
        "all_attn_weights = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for X_bag, y in tqdm(test_loader, desc=\"Evaluating\", leave=False):\n",
        "        X_bag, y = X_bag.to(device), y.to(device)\n",
        "\n",
        "        # 1. Slice-level prediction (also getting attention weights)\n",
        "        bag_logits,attn_weights = model(X_bag, return_attn_weights=True)\n",
        "        bag_pred = bag_logits.argmax(dim=1)\n",
        "        all_preds.extend(bag_pred.cpu().numpy())\n",
        "        all_trues.extend(y.cpu().numpy())\n",
        "\n",
        "        # 2. Patch-level prediction\n",
        "        patch_logits = model(X_bag, return_patch_logits=True)\n",
        "        patch_pred = patch_logits.argmax(dim=2).squeeze(0).cpu().numpy()\n",
        "        patch_labels = y.cpu().item() * np.ones_like(patch_pred)\n",
        "        all_patch_preds.extend(patch_pred)\n",
        "        all_patch_trues.extend(patch_labels)\n",
        "\n",
        "        # 3. Save Attention Weights (for visualization)\n",
        "        attn_weights = attn_weights.squeeze(0).cpu().numpy()\n",
        "        all_attn_weights.append(attn_weights)\n",
        "\n",
        "# 4. Case Level Majority Vote Aggregation\n",
        "slice_keys = list(test_patches.keys())\n",
        "case_preds = defaultdict(list)\n",
        "case_trues = {}\n",
        "\n",
        "for i in range(len(all_preds)):\n",
        "\n",
        "    pred = all_preds[i]\n",
        "    true_label = all_trues[i]\n",
        "    case_id = slice_keys[i][0]\n",
        "    case_preds[case_id].append(pred)\n",
        "\n",
        "    # Map the true label to the case_id\n",
        "    case_trues[case_id] = true_label\n",
        "\n",
        "# Majority vote per case (same logic as before)\n",
        "final_preds = []\n",
        "final_trues = []\n",
        "for case_id in sorted(case_preds.keys()):\n",
        "    votes = case_preds[case_id]\n",
        "    # Use max with key=votes.count for majority vote\n",
        "    maj_pred = max(set(votes), key=votes.count)\n",
        "    final_preds.append(maj_pred)\n",
        "    final_trues.append(case_trues[case_id])\n",
        "\n",
        "# Report\n",
        "print(\"=== Aggregated Case-Level Classification Report ===\")\n",
        "print(classification_report(final_trues, final_preds, target_names=['Benign', 'High-grade CMIL']))\n",
        "\n",
        "print(\"=== Slice-Level Classification Report ===\")\n",
        "print(classification_report(all_trues, all_preds, target_names=['Benign', 'High-grade CMIL'], labels=[0,1]))\n",
        "\n",
        "print(\"\\n=== Patch-Level Classification Report (weak labels) ===\")\n",
        "print(classification_report(all_patch_trues, all_patch_preds, target_names=['Benign', 'High-grade CMIL'], labels=[0,1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Zaordx7zClo"
      },
      "outputs": [],
      "source": [
        "def plot_confusion_matrix(trues, preds, title):\n",
        "    cm = confusion_matrix(trues, preds)\n",
        "    plt.figure(figsize=(6, 5))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=['Benign', 'High-grade CMIL'],\n",
        "                yticklabels=['Benign', 'High-grade CMIL'])\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"True\")\n",
        "    plt.title(title)\n",
        "    plt.show()\n",
        "\n",
        "# --- Plotting the matrices ---\n",
        "\n",
        "# 1. Slice-Level and Patch-Level\n",
        "for name, preds, trues in [\n",
        "    (\"Slice-Level\", all_preds, all_trues),\n",
        "    (\"Patch-Level\", all_patch_preds, all_patch_trues)\n",
        "]:\n",
        "    plot_confusion_matrix(trues, preds, f\"{name} Confusion Matrix\")\n",
        "\n",
        "# 2. Aggregated Case-Level\n",
        "plot_confusion_matrix(\n",
        "    final_trues,\n",
        "    final_preds,\n",
        "    \"Aggregated Case-Level Confusion Matrix (Majority Vote)\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E93iV8KvzFZj"
      },
      "outputs": [],
      "source": [
        "def visualize_top_attended_patches(test_ds, all_attn_weights, all_preds, all_trues, num_cases=3, top_k=5):\n",
        "    # all_preds and all_trues should be patch-level prediction\n",
        "    selected_indices = random.sample(range(len(test_ds)), num_cases)\n",
        "\n",
        "    for idx in selected_indices:\n",
        "        # --- Retrieve Cached Results ---\n",
        "        bag, _ = test_ds[idx]\n",
        "\n",
        "        # Retrieve the pre-computed results\n",
        "        label = all_trues[idx]\n",
        "        pred = all_preds[idx]\n",
        "        attn_weights = all_attn_weights[idx]\n",
        "        correct = (pred == label)\n",
        "\n",
        "        # --- Visualization Logic (Same as before) ---\n",
        "        patch_paths = test_ds.bags[idx]\n",
        "        top_indices = attn_weights.argsort()[-top_k:][::-1]\n",
        "\n",
        "        print(f\"\\nðŸ§ª Case #{idx}: True label = {label}, Predicted = {pred}, Correct = {correct}\")\n",
        "        print(\"Top patches with highest attention:\")\n",
        "\n",
        "        plt.figure(figsize=(15, 3))\n",
        "        for i, patch_idx in enumerate(top_indices):\n",
        "            patch_path = patch_paths[patch_idx]\n",
        "            # Ensure the path is correct and the image exists\n",
        "            try:\n",
        "                img = Image.open(patch_path)\n",
        "            except FileNotFoundError:\n",
        "                print(f\"Error: Patch image not found at {patch_path}. Skipping.\")\n",
        "                continue\n",
        "\n",
        "            weight = attn_weights[patch_idx]\n",
        "\n",
        "            print(f\"  - {os.path.basename(patch_path)}: attention = {weight:.4f}\")\n",
        "\n",
        "            plt.subplot(1, top_k, i + 1)\n",
        "            plt.imshow(img)\n",
        "            plt.axis('off')\n",
        "            plt.title(f\"attn={weight:.3f}\")\n",
        "        plt.suptitle(f\"Case {idx} | True: {label} | Pred: {pred} | Correct: {correct}\")\n",
        "        plt.tight_layout()\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bVZRdjUBzGxX"
      },
      "outputs": [],
      "source": [
        "visualize_top_attended_patches(test_ds, all_attn_weights, all_patch_preds, all_patch_trues, num_cases=100, top_k=2)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}