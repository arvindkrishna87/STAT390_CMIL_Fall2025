{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "iILjky4pEAdG"
   },
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "from collections import OrderedDict\n",
    "\n",
    "# Data handling and visualization libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# PyTorch and TorchVision libraries for deep learning\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms, datasets\n",
    "from PIL import Image\n",
    "\n",
    "# Scikit-Learn for evaluation metrics and data splitting|\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "\n",
    "# Imbalanced-learn for oversampling to address class imbalance\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import functional as F\n",
    "from PIL import Image\n",
    "from PIL import Image\n",
    "from PIL import UnidentifiedImageError\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os, re, random\n",
    "from collections import defaultdict, Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from google.colab import drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5ctwMSZTEK9M",
    "outputId": "d1d1c693-7f72-4d79-db56-4eef815f68a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# â”€â”€â”€ 1) MOUNT GOOGLE DRIVE â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "vGs2GP7zFypq"
   },
   "outputs": [],
   "source": [
    "# â”€â”€â”€ LOAD LABELS & BUILD CLASS MAP â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "labels = pd.read_csv(\n",
    "    \"/content/drive/MyDrive/case_grade_match.csv\"\n",
    ").drop(index=64, errors='ignore').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "id": "K2KupvZ1GBIU",
    "outputId": "fae5f3b4-505e-4bbf-cbed-98b311dbb29b"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"labels\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"Case\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 63,\n        \"max\": 67,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          64,\n          67,\n          63\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Class\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 3,\n        \"max\": 4,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          4,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-e991cf17-b2f3-4356-889d-d05ed29dafcf\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>63</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>66</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>67</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e991cf17-b2f3-4356-889d-d05ed29dafcf')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-e991cf17-b2f3-4356-889d-d05ed29dafcf button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-e991cf17-b2f3-4356-889d-d05ed29dafcf');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-db0fd335-bd47-445c-9778-44a7abda3715\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-db0fd335-bd47-445c-9778-44a7abda3715')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-db0fd335-bd47-445c-9778-44a7abda3715 button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "    Case  Class\n",
       "62    63      3\n",
       "63    64      3\n",
       "64    66      3\n",
       "65    67      4"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note that case 65 is not included in the analysis as it was not labelled\n",
    "labels.loc[62:65,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f16hcoFCV8ir"
   },
   "outputs": [],
   "source": [
    "filtered_patches_dir = '/content/drive/My Drive/CMIL_SP2025_Patches_Apr27'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Lzujk98hVyog",
    "outputId": "03211e1d-da67-4e61-b6e0-bb12d10ac372"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83717"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_files = os.listdir(filtered_patches_dir)\n",
    "len(all_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "vBovTKpdPl5D"
   },
   "outputs": [],
   "source": [
    "# === Slice-Level Grouping ===\n",
    "def group_patches_by_slice(root_dir):\n",
    "    case_slices = defaultdict(list)\n",
    "    for root, _, files in os.walk(root_dir):\n",
    "        for filename in files:\n",
    "            if filename.endswith(\".png\"):\n",
    "                match = re.match(r\"case_(\\d+)_([a-z]+_\\d+)_\", filename) #check if some patches are named differently\n",
    "                if match:\n",
    "                    case_id = int(match.group(1))\n",
    "                    slice_id = match.group(2)\n",
    "                    key = (case_id, slice_id)\n",
    "                    case_slices[key].append(os.path.join(root, filename))\n",
    "    return case_slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "O33OgeH8PpTs"
   },
   "outputs": [],
   "source": [
    "# === Load Patches by Slice ===\n",
    "patches = group_patches_by_slice(filtered_patches_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3ZOnUpxTbnrW",
    "outputId": "b09c3893-071a-43e2-9608-a94d22294d98"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "350"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B5hT39kHRPuG",
    "outputId": "25e43fd7-e66c-4bf5-cd2b-f889794f33f3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79909"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tot_patches = 0\n",
    "for ke in patches.keys():\n",
    "  tot_patches = tot_patches + len(patches[ke])\n",
    "tot_patches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kAGh7_L2XOdZ"
   },
   "source": [
    "Some patches are getting lost (need to make the 'match = re.match(....)' code more general)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "dklmcj3LTZbg"
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "id": "2F55HKGHTfes"
   },
   "outputs": [],
   "source": [
    "# Training transform (augmented)\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "JvuJRLKnTdXG"
   },
   "outputs": [],
   "source": [
    "# === Build Label Map by Slice ===\n",
    "slice_to_class = {}\n",
    "valid_classes = [1.0, 3.0, 4.0]\n",
    "for (case_id, slice_id), paths in patches.items():\n",
    "    raw_label = labels.loc[labels['Case'] == case_id, 'Class']\n",
    "    if not raw_label.empty and raw_label.item() in valid_classes:\n",
    "        label = 0 if raw_label.item() == 1.0 else 1\n",
    "        slice_to_class[(case_id, slice_id)] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dnPMgZEVaArv",
    "outputId": "59302409-fb2f-403b-d88d-9bf21b45bf4c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "338"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(slice_to_class) # Low-grade slices are removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iMd2EPH8clyX",
    "outputId": "de218b40-c295-4d6b-f170-5ef3d6a5c118"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slice_to_class[(106, 'match_1')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "id": "mHOQiVV-czTU"
   },
   "outputs": [],
   "source": [
    "# === Stratified Split by Slice ===\n",
    "slices_by_class = defaultdict(list)\n",
    "for key, label in slice_to_class.items():\n",
    "    slices_by_class[label].append(key) # Dictonary of length 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PcRR60GYc4He",
    "outputId": "2fb1a082-1421-4def-e94b-7630ff1975c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([1, 0])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slices_by_class.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bYt7GPXodEww",
    "outputId": "c104146a-a2ad-432e-9ddd-563963f2c6cf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(25, 'match_1'), (25, 'match_2')]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slices_by_class[0][0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "id": "0BnH_qQ5eWQo"
   },
   "outputs": [],
   "source": [
    "train_slices, val_slices, test_slices = [], [], []\n",
    "for label, slice_keys in slices_by_class.items():\n",
    "    train, temp = train_test_split(slice_keys, test_size=0.4, random_state=42)\n",
    "    val, test = train_test_split(temp, test_size=0.5, random_state=42)\n",
    "    train_slices += train\n",
    "    val_slices += val\n",
    "    test_slices += test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yA8usoWVfX4_",
    "outputId": "00572679-1992-44a2-f578-b7be82218ba8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9dhV_lpxfTLB",
    "outputId": "69d02590-f645-4f73-9ff6-0643713a6f7b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(25, 'match_1'), (25, 'match_2')]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slice_keys[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "55AqRDFffhBQ",
    "outputId": "d9e16d2a-041a-4e53-d7c0-d6057088300b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "202"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_slices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hUxoM8LifjkE",
    "outputId": "a68211ad-b947-4949-e63b-7f7abe7409ac"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_slices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xokMN7iBflaH",
    "outputId": "6a5c25fc-b817-4003-bf25-15cc61a83d2f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_slices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WITEo5cifpUa",
    "outputId": "c78a87ea-d183-4219-bcf1-08046acd27b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 7, 9, 11, 12, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 30, 32, 34, 36, 38, 40, 41, 42, 43, 44, 45, 47, 48, 50, 52, 54, 56, 57, 58, 59, 61, 63, 64, 66, 68, 69, 70, 72, 73, 75, 77, 78, 79, 80, 84, 85, 86, 87, 88, 89, 90, 91, 93, 94, 95, 96, 97, 98, 100, 101, 104, 106]\n"
     ]
    }
   ],
   "source": [
    "ele_list_train = []\n",
    "for ele in train_slices:\n",
    "  if ele[0] not in ele_list_train:\n",
    "    ele_list_train.append(ele[0])\n",
    "ele_list_train.sort()\n",
    "print(ele_list_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wv2arZ9EiTnK",
    "outputId": "24711185-a1b3-453a-ecc7-ec4b882ef349"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3, 12, 14, 15, 18, 19, 21, 22, 24, 25, 26, 27, 28, 32, 34, 36, 38, 40, 41, 42, 50, 55, 56, 57, 60, 63, 66, 68, 69, 70, 72, 73, 82, 83, 91, 92, 93, 94, 96, 97, 98, 99, 104]\n"
     ]
    }
   ],
   "source": [
    "ele_list_test = []\n",
    "for ele in test_slices:\n",
    "  if ele[0] not in ele_list_test:\n",
    "    ele_list_test.append(ele[0])\n",
    "ele_list_test.sort()\n",
    "print(ele_list_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "999KuzlVlqTY",
    "outputId": "23a21c4b-e025-426d-b799-00d119104e20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3, 12, 14, 15, 18, 19, 21, 22, 24, 25, 26, 27, 28, 32, 34, 36, 38, 40, 41, 42, 50, 56, 57, 63, 66, 68, 69, 70, 72, 73, 91, 93, 94, 96, 97, 98, 104]\n"
     ]
    }
   ],
   "source": [
    "print(list(set(ele_list_train) & set(ele_list_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sUNXnN8KmnaQ",
    "outputId": "685eb4e4-8fd8-4d6d-aa18-a895f1f2ad92"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(set(ele_list_train) & set(ele_list_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M2VEYL_KmpYd",
    "outputId": "72b02fb8-5494-4a37-c9e3-8a43440b093a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ele_list_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dSTLe2Eof2Xh",
    "outputId": "87098b6e-9884-4ee4-d9b1-e628492913fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 'unmatched_3')\n",
      "(2, 'unmatched_2')\n",
      "(2, 'unmatched_1')\n"
     ]
    }
   ],
   "source": [
    "for ele in train_slices:\n",
    "  if ele[0] == 2:\n",
    "    print(ele)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LsY6xPbvi9tj",
    "outputId": "8b72efa8-2935-40a8-d2d0-0c5a4deba533"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 'match_1')\n"
     ]
    }
   ],
   "source": [
    "for ele in test_slices:\n",
    "  if ele[0] == 2:\n",
    "    print(ele)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "id": "ZMXtHxiejB5m"
   },
   "outputs": [],
   "source": [
    "train_patches = {k: patches[k] for k in train_slices}\n",
    "val_patches   = {k: patches[k] for k in val_slices}\n",
    "test_patches  = {k: patches[k] for k in test_slices}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GKVYPhsEkyz4",
    "outputId": "a88e0ac4-b732-4cc3-89d6-6e39902a37e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ Dropped slices with no 'h&e' patches: [(18, 'unmatched_4'), (72, 'unmatched_5'), (15, 'match_2'), (50, 'match_4'), (38, 'match_29'), (38, 'match_22'), (15, 'unmatched_10'), (38, 'match_28'), (15, 'match_1'), (15, 'unmatched_11'), (27, 'unmatched_9'), (21, 'match_1'), (24, 'unmatched_9'), (27, 'match_2')]\n",
      "âš ï¸ Dropped slices with no 'h&e' patches: [(104, 'match_15'), (15, 'unmatched_12'), (73, 'unmatched_3'), (23, 'match_1'), (22, 'unmatched_13'), (22, 'unmatched_12'), (27, 'unmatched_8')]\n",
      "âš ï¸ Dropped slices with no 'h&e' patches: [(38, 'match_27'), (50, 'match_5'), (73, 'unmatched_4'), (15, 'unmatched_13'), (72, 'unmatched_6'), (24, 'unmatched_10'), (27, 'unmatched_1'), (21, 'unmatched_4')]\n"
     ]
    }
   ],
   "source": [
    "# === Filter to H&E Only ===\n",
    "\n",
    "def filter_by_stain(d, keyword):\n",
    "    out, dropped = {}, []\n",
    "    for k, paths in d.items():\n",
    "        filtered = [p for p in paths if keyword.lower() in os.path.basename(p).lower()]\n",
    "        if filtered:\n",
    "            out[k] = filtered\n",
    "        else:\n",
    "            dropped.append(k)\n",
    "    if dropped:\n",
    "        print(f\"âš ï¸ Dropped slices with no '{keyword}' patches: {dropped}\")\n",
    "    return out\n",
    "\n",
    "\n",
    "train_patches = filter_by_stain(train_patches, \"h&e\")\n",
    "val_patches   = filter_by_stain(val_patches, \"h&e\")\n",
    "test_patches  = filter_by_stain(test_patches, \"h&e\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CVb2JuRyomZQ",
    "outputId": "f9dad97f-2841-44d5-9234-05f9dc11930e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "188"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "id": "nTQ1hoQZq2aU"
   },
   "outputs": [],
   "source": [
    "# === MILDataset with slice-level keys ===\n",
    "class SliceMILDataset(Dataset):\n",
    "    def __init__(self, patch_dict, label_map, transform=None, emergency_cap=800):\n",
    "      #emergency_cap: upper limit on how many patches per bag to include, why have a limit? how set the limit?\n",
    "      #If a bag has too many patches (say 3000), only randomly keeps up to emergency_cap (default 800)\n",
    "      #Prevents out-of-memory errors during training. - needed or not?\n",
    "      #transform: optional torchvision transform (e.g., resizing, normalization) - same as manual?\n",
    "        self.transform = transform\n",
    "        self.emergency_cap = emergency_cap\n",
    "        # self.bags: list of lists of image paths (each â€œbagâ€ = slice).\n",
    "        # self.labels: list of corresponding labels for each bag.\n",
    "        self.bags, self.labels = [], []\n",
    "        for slice_key, paths in patch_dict.items():\n",
    "            if slice_key in label_map:#must be, why the need to check if slice also has a known label in label_map\n",
    "                self.bags.append(paths)\n",
    "                self.labels.append(label_map[slice_key])\n",
    "\n",
    "    # Required for PyTorch datasets â€” tells how many samples (bags) exist.\n",
    "    # Enables len(dataset) to work and is used by DataLoader for batching.\n",
    "    def __len__(self): return len(self.bags)\n",
    "\n",
    "\n",
    "    # The method below is called whenever PyTorch asks for a sample.\n",
    "    # Retrieves the list of patch file paths for that bag.\n",
    "    def __getitem__(self, idx):\n",
    "        paths = self.bags[idx] # idx is the index of the bag you want.\n",
    "        imgs = []\n",
    "        for p in paths:   # Loops through each patch path in the bag.\n",
    "            try:\n",
    "                img = Image.open(p).convert('RGB')#Change the color transformation - YCbCr, HSV\n",
    "                if self.transform: # Applies transforms if provided (resize, normalize, etc.)\n",
    "                    img = self.transform(img)\n",
    "                imgs.append(img)\n",
    "            except:\n",
    "                continue #why try-except, what error? Why corrupt patches?\n",
    "        if len(imgs) == 0:\n",
    "            raise ValueError(f\"No usable patches in slice {paths}\")\n",
    "        if self.emergency_cap and len(imgs) > self.emergency_cap:\n",
    "            imgs = random.sample(imgs, self.emergency_cap)\n",
    "        return torch.stack(imgs), torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        #Stacks all transformed image tensors into a single tensor of shape:\n",
    "        #(num_patches, C, H, W)\n",
    "        #(e.g., (500, 3, 224, 224) for 500 patches).\n",
    "        #Converts the label to a PyTorch tensor of type long (needed for classification loss).\n",
    "        #Returns (bag_tensor, label_tensor) as one sample.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "id": "AiL7l1Bmt0Aw"
   },
   "outputs": [],
   "source": [
    "# this pools the patch level features into single bag level representation for MIL\n",
    "class AttentionPool(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=128):\n",
    "      #input_dim: the dimensionality of each input feature vector (e.g., 512 if youâ€™re using a CNN encoder like ResNet).\n",
    "      #hidden_dim: the size of the hidden layer used inside the attention mechanism (default = 128).\n",
    "      #This defines how much capacity the attention sub-network has to learn complex relationships.\n",
    "        super().__init__()\n",
    "        # creates small neural network to compute attention scores for each patch\n",
    "        # each patch embedding is passed through a linear layer, tanh for nonlinearity, and another linear layer to get a scalar score\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_dim, 1)\n",
    "        )\n",
    "    def forward(self, x, return_weights=False):\n",
    "        # x is of shape (B, M, D) where B is batch size or number of cases,\n",
    "        # M is number of patches per bag, and D is the embedding dimensions for each patch\n",
    "        weights = self.attention(x)     # (B, M, 1)\n",
    "        weights = torch.softmax(weights, dim=1) # softmax so that weights are positive\n",
    "        # outputs attention scores for each patch and normalized with softmax\n",
    "        # D is the embedding dimension which is size of feature vector for each patch after going through the patch classifier\n",
    "        weighted_x = (weights * x).sum(dim=1)  # (B, D)\n",
    "        # returning the raw attention weights per patch just to help with visualization of the weights for each patch\n",
    "        if return_weights:\n",
    "            return weighted_x, weights.squeeze(-1)  # (B, D), (B, M)\n",
    "        return weighted_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mPpCrdoE-zWB"
   },
   "source": [
    "# using Densenet to extract features at the patch-level, and adaptaive pooling for patch-level feature pooling\n",
    "# the patch features are passed into Attentionpool which learns the weights across patches and combines them into a single bag label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "id": "sqabQIV6-fo5"
   },
   "outputs": [],
   "source": [
    "class AttnMIL(nn.Module):\n",
    "    def __init__(self, base_model, num_classes=2, embed_dim=512):\n",
    "        super().__init__()\n",
    "        # grabbing the convolutional feature extractor from the pretrained model\n",
    "        self.features = base_model.features\n",
    "        # applying adaptive average pooling to compress to feature map of 2x2 grid\n",
    "        # you get 4 spatial vectors per patch\n",
    "        self.pool = nn.AdaptiveAvgPool2d((2,2))  # richer than (1,1) - tunable!\n",
    "        # meaning that you'll get 4 vectors per patch which will then be flattened\n",
    "        self.patch_projector = nn.Linear(base_model.classifier.in_features * 4, embed_dim)\n",
    "\n",
    "        # Attention module (your earlier class) that produces per-patch weights and returns a bag embedding (weighted sum) of size embed_dim.\n",
    "        self.attention_pool = AttentionPool(embed_dim)\n",
    "\n",
    "        # Final classifier that maps the bag embedding to logits over classes.\n",
    "        self.classifier = nn.Linear(embed_dim, num_classes)\n",
    "\n",
    "\n",
    "    def forward(self, x, return_patch_logits=False, return_attn_weights=False):\n",
    "        if x.dim() == 4: # why the need to check?\n",
    "            x = x.unsqueeze(0)\n",
    "        # typically after CNN you get 3D tensor with num channels, height and width of image\n",
    "        # but we packed the patches into a bag by case (the tensor), so B is batch size, M is number of patches per bag\n",
    "        B, M, C, H, W = x.shape\n",
    "        x = x.view(B*M, C, H, W) # put all patches in the batch together\n",
    "\n",
    "        features = self.features(x) # exxtracting cnn features for each patch, output shape: (B*M, C', H', W')\n",
    "        pooled = self.pool(features).view(B*M, -1) # pool each feature map to a 2x2 grid and flatten, output shape: (B*M, 4*C')\n",
    "        embedded = self.patch_projector(pooled).view(B, M, -1) # project each patch into shared embedding space, output shape (B, M, embed_dim)\n",
    "        # just ensuring all the patches are transformed into vectors of the same length for attention\n",
    "\n",
    "        # in order to get patch level predictions\n",
    "        # Optional per-patch logits: apply the bag classifier to each patch embedding independently. Shape (B, M, num_classes). Useful for diagnostics/auxiliary losses.\n",
    "        if return_patch_logits:\n",
    "            logits = self.classifier(embedded)  # (B, M, 2)\n",
    "            return logits\n",
    "        # returning attention weights for visualization\n",
    "        if return_attn_weights:\n",
    "            bag_emb, attn_weights = self.attention_pool(embedded, return_weights=True)\n",
    "            logits = self.classifier(bag_emb)\n",
    "            return logits, attn_weights  # bag prediction + per-patch attention scores, why logits here when returning at the end\n",
    "\n",
    "        # applying attention\n",
    "        #computing a weighted average of patch embeddings using attention, and then is passed through the classifier to get bag level prediction\n",
    "        bag_emb = self.attention_pool(embedded) #Shape: (B, embed_dim) + weights (B, M)\n",
    "        logits = self.classifier(bag_emb) # Shape: (B, 2)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# h&e\n",
    "for i in range(num_slices):\n",
    "    slice_emb[i] = self.attention_pool1(embedded)\n",
    "# Create Tensor of shape (num_slices, 512) for each stain\n",
    "# Let us sayTensor is slice_emb\n",
    "\n",
    "for stain in (): #loop over the 3 stains\n",
    "    stain_emb[i] = self.attention_pool2(slice_emb)\n",
    "# Create Tensor of shape (3, 512) for each case\n",
    "# Let us say Tensor is stain_emb\n",
    "\n",
    "case_emb = self.attention_pool3(stain_emb)\n",
    "# add more layers - Noah\n",
    "logits = self.classifier(case_emb) # Shape: (B, 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6JuOK_etMoUL"
   },
   "source": [
    "# What is the effect of M varying in each bag?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "id": "Ny2nqVDsMltd"
   },
   "outputs": [],
   "source": [
    "# Set up datasets\n",
    "# Set up slice-based MIL datasets\n",
    "# dict mapping slice_key -> list_of_patch_paths for the train split.\n",
    "# dict mapping slice_key -> class_label.\n",
    "# image augmentations for training (e.g., flips/crops/normalization).\n",
    "train_ds = SliceMILDataset(train_patches, slice_to_class, transform=train_transform)\n",
    "\n",
    "# Uses (usually) lighter or no augmentation (transform) to mimic evaluation conditions.\n",
    "val_ds   = SliceMILDataset(val_patches, slice_to_class, transform=transform)\n",
    "\n",
    "# emergency_cap=None disables the cap on patches per bag (use all patches). Helpful to evaluate full performance without subsampling.\n",
    "test_ds  = SliceMILDataset(test_patches, slice_to_class, transform=transform, emergency_cap=None)\n",
    "\n",
    "# help generalize better and reduce overfitting\n",
    "# Wraps train_ds in a PyTorch DataLoader.\n",
    "# batch_size=1: in MIL, each bag (slice) can contain a variable number of patches; batching multiple bags together often requires padding/collate tricks. Why? Is it because bag sizes are different? Using 1 bag per batch keeps it simple and memory-safe.\n",
    "# shuffle=True: randomizes bag order each epoch â†’ improves generalization and reduces overfitting.\n",
    "train_loader = DataLoader(train_ds, batch_size=1, shuffle=True)\n",
    "# don't want to shuffle so taht you get consistent, repeatable evaluation\n",
    "val_loader   = DataLoader(val_ds, batch_size=1, shuffle=False)\n",
    "test_loader  = DataLoader(test_ds, batch_size=1, shuffle=False)\n",
    "\n",
    "# If bags vary wildly in size and you want larger batches, you can implement a custom collate_fn to pad/truncate bags, but that adds complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BMmsiT2-UuLK",
    "outputId": "a0c89120-8acf-4128-860e-cfc0e86d5497"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¹ Train Split\n",
      "Cases: 188\n",
      "Patches: 22356\n",
      "Class distribution: {1: 122, 0: 66}\n",
      "Slices (unique IDs): 26\n",
      "\n",
      "ðŸ”¹ Validation Split\n",
      "Cases: 61\n",
      "Patches: 6724\n",
      "Class distribution: {1: 41, 0: 20}\n",
      "Slices (unique IDs): 22\n",
      "\n",
      "ðŸ”¹ Test Split\n",
      "Cases: 60\n",
      "Patches: 7244\n",
      "Class distribution: {1: 39, 0: 21}\n",
      "Slices (unique IDs): 15\n"
     ]
    }
   ],
   "source": [
    "def summarize_split(patch_dict, label_map=None, split_name=\"\"):\n",
    "    # Count cases\n",
    "    num_cases = len(patch_dict)\n",
    "\n",
    "    # Count total patches\n",
    "    total_patches = sum(len(paths) for paths in patch_dict.values())\n",
    "\n",
    "    # Count per class (if label map provided)\n",
    "    class_counts = Counter()\n",
    "    if label_map:\n",
    "        class_counts.update([label_map[c] for c in patch_dict.keys() if c in label_map])\n",
    "\n",
    "    # Count unique slice IDs (if present in patch filenames)\n",
    "    slice_set = set()\n",
    "    for paths in patch_dict.values():\n",
    "        for path in paths:\n",
    "            # Extract slice identifier after 2nd underscore (e.g., unmatched_2 from case_01_unmatched_2_patch43.png)\n",
    "            match = re.search(r\"case_\\d+_(\\w+_\\d+)\", os.path.basename(path))\n",
    "            if match:\n",
    "                slice_set.add(match.group(1))\n",
    "\n",
    "    # Output\n",
    "    print(f\"\\nðŸ”¹ {split_name} Split\")\n",
    "    print(f\"Cases: {num_cases}\")\n",
    "    print(f\"Patches: {total_patches}\")\n",
    "    if class_counts:\n",
    "        print(f\"Class distribution: {dict(class_counts)}\")\n",
    "    print(f\"Slices (unique IDs): {len(slice_set)}\")\n",
    "\n",
    "# Run for all splits\n",
    "summarize_split(train_patches, slice_to_class, split_name=\"Train\")\n",
    "summarize_split(val_patches, slice_to_class, split_name=\"Validation\")\n",
    "summarize_split(test_patches, slice_to_class, split_name=\"Test\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
