{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iILjky4pEAdG"
      },
      "outputs": [],
      "source": [
        "# Standard library imports\n",
        "import os\n",
        "import re\n",
        "import random\n",
        "import shutil\n",
        "from datetime import datetime\n",
        "from collections import OrderedDict\n",
        "\n",
        "# Data handling and visualization libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# PyTorch and TorchVision libraries for deep learning\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import torchvision\n",
        "import torchvision.models as models\n",
        "from torchvision import transforms, datasets\n",
        "from PIL import Image\n",
        "\n",
        "# Scikit-Learn for evaluation metrics and data splitting|\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
        "\n",
        "# Imbalanced-learn for oversampling to address class imbalance\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "\n",
        "from torchvision import transforms\n",
        "from torchvision.transforms import functional as F\n",
        "from PIL import Image\n",
        "from PIL import Image\n",
        "from PIL import UnidentifiedImageError\n",
        "from tqdm import tqdm\n",
        "\n",
        "import os, re, random\n",
        "from collections import defaultdict, Counter\n",
        "from sklearn.model_selection import train_test_split\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ctwMSZTEK9M",
        "outputId": "724da24f-2d00-417e-d635-ee9f4bc9a160"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# ─── 1) MOUNT GOOGLE DRIVE ──────────────────────────────────────────────\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vGs2GP7zFypq"
      },
      "outputs": [],
      "source": [
        "# ─── LOAD LABELS & BUILD CLASS MAP ───────────────────────────────────────\n",
        "labels = pd.read_csv(\n",
        "    \"/content/drive/MyDrive/case_grade_match.csv\"\n",
        ").drop(index=64, errors='ignore').reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "K2KupvZ1GBIU",
        "outputId": "9907bb67-df46-42c5-f88a-60f97addaf98"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"labels\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"Case\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 63,\n        \"max\": 67,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          64,\n          67,\n          63\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Class\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 3,\n        \"max\": 4,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          4,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-b38485b3-641a-4456-93f4-b0b06c06c2b2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Case</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>63</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>64</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>66</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65</th>\n",
              "      <td>67</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b38485b3-641a-4456-93f4-b0b06c06c2b2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b38485b3-641a-4456-93f4-b0b06c06c2b2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b38485b3-641a-4456-93f4-b0b06c06c2b2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-435ece44-aabd-4c61-9371-8004bc6e1163\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-435ece44-aabd-4c61-9371-8004bc6e1163')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-435ece44-aabd-4c61-9371-8004bc6e1163 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "    Case  Class\n",
              "62    63      3\n",
              "63    64      3\n",
              "64    66      3\n",
              "65    67      4"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Note that case 65 is not included in the analysis as it was not labelled\n",
        "labels.loc[62:65,:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8LJTnANPj2T",
        "outputId": "ee3f95ae-d663-40f1-ebed-1caa0f8b47c1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "filtered_patches_dir = '/content/drive/MyDrive/CMIL_SP2025_Patches_Apr27'\n",
        "os.path.exists(filtered_patches_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lzujk98hVyog",
        "outputId": "d760d348-fbdc-45f5-899b-cce3355da81d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "83717"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "all_files = os.listdir(filtered_patches_dir)\n",
        "len(all_files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vBovTKpdPl5D"
      },
      "outputs": [],
      "source": [
        "# === Slice-Level Grouping ===\n",
        "\n",
        "# Edit 10/19: identified scenario where patches are not being matched:\n",
        "#     1) missing space between 'match' / 'unmatched' and number, eg. case_38_match14_h&e_patch25.png\n",
        "#     2) Additionally, some names include 'labels' (not relevant to this regex which is only looking at case matching but thought I would flag),\n",
        "#         eg. case_82_unmatched3_h&e-labels_patch32.png\n",
        "def group_patches_by_slice(root_dir):\n",
        "    case_slices = defaultdict(list)\n",
        "    # list of unconventionally-named patches\n",
        "    invalid_file_names = []\n",
        "    flexibility_needed_counter = 0\n",
        "    for root, _, files in os.walk(root_dir):\n",
        "        for filename in files:\n",
        "            if filename.endswith(\".png\"):\n",
        "              #  match = re.match(r\"case_(\\d+)_([\\w&\\-]+_\\d+)_\", filename)\n",
        "                match = re.match(r\"case_(\\d+)_([a-z]+_\\d+)_\", filename) #check if some patches are named differently\n",
        "                if match:\n",
        "                    case_id = int(match.group(1))\n",
        "                    slice_id = match.group(2)\n",
        "                    key = (case_id, slice_id)\n",
        "                    case_slices[key].append(os.path.join(root, filename))\n",
        "\n",
        "                    continue\n",
        "                # if a file doesn't match, try regex without \"_\" between \"match\" / \"unmatched\" and number\n",
        "                match = re.match(r\"case_(\\d+)_([a-z]+\\d+)_\", filename)\n",
        "                if match:\n",
        "                    case_id = int(match.group(1))\n",
        "                    slice_id = match.group(2)\n",
        "                    # adding underscore between \"match\" / \"unmatched\" and number\n",
        "                    slice_id = re.sub(r'([A-Za-z])(\\d)', r'\\1_\\2', slice_id)\n",
        "                    key = (case_id, slice_id)\n",
        "                    case_slices[key].append(os.path.join(root, filename))\n",
        "                    flexibility_needed_counter += 1\n",
        "\n",
        "                    continue\n",
        "                invalid_file_names.append(os.path.join(root, filename))\n",
        "\n",
        "    # Print summary of invalid files\n",
        "    if invalid_file_names:\n",
        "        print(f\"Found {len(invalid_file_names)} files not following naming convention:\")\n",
        "        for f in invalid_file_names:\n",
        "            print(\"  \", f)\n",
        "    else:\n",
        "        print(f\"All {flexibility_needed_counter} invalid file names were handled.\")\n",
        "    return case_slices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O33OgeH8PpTs",
        "outputId": "2402e3fb-b731-4529-84ab-8be3d47f45d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All 3808 invalid file names were handled.\n"
          ]
        }
      ],
      "source": [
        "# === Load Patches by Slice ===\n",
        "patches = group_patches_by_slice(filtered_patches_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ZOnUpxTbnrW",
        "outputId": "1fdfa2f5-5cdd-418c-e603-f441f0612c05"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "378"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(patches)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B5hT39kHRPuG",
        "outputId": "c9d6565e-8536-4f8e-b1ca-6375acf34375"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "83717"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tot_patches = 0\n",
        "for ke in patches.keys():\n",
        "  tot_patches = tot_patches + len(patches[ke])\n",
        "tot_patches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dklmcj3LTZbg"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2F55HKGHTfes"
      },
      "outputs": [],
      "source": [
        "# Training transform (augmented)\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JvuJRLKnTdXG"
      },
      "outputs": [],
      "source": [
        "# === Build Label Map by Slice ===\n",
        "slice_to_class = {}\n",
        "valid_classes = [1.0, 3.0, 4.0]\n",
        "for (case_id, slice_id), paths in patches.items():\n",
        "    raw_label = labels.loc[labels['Case'] == case_id, 'Class']\n",
        "    if not raw_label.empty and raw_label.item() in valid_classes:\n",
        "        label = 0 if raw_label.item() == 1.0 else 1\n",
        "        slice_to_class[(case_id, slice_id)] = label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dnPMgZEVaArv",
        "outputId": "4668f5dd-d967-44bd-9abc-4263afc20add"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "366"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(slice_to_class) # Low-grade slices are removed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iMd2EPH8clyX",
        "outputId": "523c9c57-6551-432c-aff7-41de21c16197"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "slice_to_class[(106, 'match_1')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mHOQiVV-czTU"
      },
      "outputs": [],
      "source": [
        "# === Stratified Split by Slice ===\n",
        "slices_by_class = defaultdict(list)\n",
        "for key, label in slice_to_class.items():\n",
        "    slices_by_class[label].append(key) # Dictonary of length 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PcRR60GYc4He",
        "outputId": "21b50007-48c5-49ad-b92f-c38e24098ce1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys([1, 0])"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "slices_by_class.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bYt7GPXodEww",
        "outputId": "88fcf2f5-8451-4fb7-c490-532ff758dc6f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "86"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# number of cases\n",
        "unique_case = {t[0] for v in slices_by_class.values() for t in v}\n",
        "len(unique_case)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D1tz-StATKNd"
      },
      "outputs": [],
      "source": [
        "def split_by_case_stratified(slices_by_class, random_state=42):\n",
        "    # 1) Build case -> label map and validate no mixed-label cases\n",
        "    case_to_labels = defaultdict(set)\n",
        "    for label, items in slices_by_class.items():\n",
        "        for case_id, _ in items:\n",
        "            case_to_labels[case_id].add(label)\n",
        "    mixed = {cid: labs for cid, labs in case_to_labels.items() if len(labs) > 1}\n",
        "    if mixed:\n",
        "        raise ValueError(f\"Found cases with mixed labels (would cause leakage): {mixed}\")\n",
        "\n",
        "    # Flatten to case list and aligned labels\n",
        "    case_ids = []\n",
        "    case_labels = []\n",
        "    for cid, labs in case_to_labels.items():\n",
        "        case_ids.append(cid)\n",
        "        case_labels.append(next(iter(labs)))  # the single label for this case\n",
        "\n",
        "    # 2) Split *cases* with stratification by case-level label\n",
        "    # 60% train, 40% temp\n",
        "    case_train, case_temp, y_train, y_temp = train_test_split(\n",
        "        case_ids, case_labels, test_size=0.4, stratify=case_labels, random_state=random_state\n",
        "    )\n",
        "    # temp -> 50/50 to make 20%/20% val/test\n",
        "    case_val, case_test, _, _ = train_test_split(\n",
        "        case_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=random_state\n",
        "    )\n",
        "\n",
        "    case_train = set(case_train)\n",
        "    case_val   = set(case_val)\n",
        "    case_test  = set(case_test)\n",
        "\n",
        "    # 3) Map case splits back to slice-level lists (no leakage)\n",
        "    train_slices, val_slices, test_slices = [], [], []\n",
        "    for label, items in slices_by_class.items():\n",
        "        for case_id, slice_key in items:\n",
        "            if case_id in case_train:\n",
        "                train_slices.append((case_id, slice_key))\n",
        "            elif case_id in case_val:\n",
        "                val_slices.append((case_id, slice_key))\n",
        "            elif case_id in case_test:\n",
        "                test_slices.append((case_id, slice_key))\n",
        "            # else: shouldn't happen\n",
        "\n",
        "    return train_slices, val_slices, test_slices\n",
        "\n",
        "train_slices, val_slices, test_slices = split_by_case_stratified(slices_by_class)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FOUGt3_3UJ9U",
        "outputId": "4ac752ba-d4cc-4439-8fe5-cb82ab0b09e4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "set()"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# check train, test and validation set doesnt have overlapping cases\n",
        "set([slice[0] for slice in train_slices]) & set([slice[0] for slice in test_slices]) & set([slice[0] for slice in val_slices])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-vsvdHMUVlE",
        "outputId": "54930d3c-b02c-404f-e439-d98a6c3238bd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "86"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# number of cases after spliting\n",
        "len(set([slice[0] for slice in train_slices]) | set([slice[0] for slice in test_slices]) | set([slice[0] for slice in val_slices]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZMXtHxiejB5m"
      },
      "outputs": [],
      "source": [
        "train_patches = {k: patches[k] for k in train_slices}\n",
        "val_patches   = {k: patches[k] for k in val_slices}\n",
        "test_patches  = {k: patches[k] for k in test_slices}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nTQ1hoQZq2aU"
      },
      "outputs": [],
      "source": [
        "# === MILDataset with slice-level keys ===\n",
        "class SliceMILDataset(Dataset):\n",
        "    def __init__(self, patch_dict, label_map, transform=None, emergency_cap=800):\n",
        "      #emergency_cap: upper limit on how many patches per bag to include, why have a limit? how set the limit?\n",
        "      #If a bag has too many patches (say 3000), only randomly keeps up to emergency_cap (default 800)\n",
        "      #Prevents out-of-memory errors during training. - needed or not?\n",
        "      #transform: optional torchvision transform (e.g., resizing, normalization) - same as manual?\n",
        "        self.transform = transform\n",
        "        self.emergency_cap = emergency_cap\n",
        "        # self.bags: list of lists of image paths (each “bag” = slice).\n",
        "        # self.labels: list of corresponding labels for each bag.\n",
        "        self.bags, self.labels = [], []\n",
        "        for slice_key, paths in patch_dict.items():\n",
        "            self.bags.append(paths)\n",
        "            self.labels.append(label_map[slice_key])\n",
        "\n",
        "    # Required for PyTorch datasets — tells how many samples (bags) exist.\n",
        "    # Enables len(dataset) to work and is used by DataLoader for batching.\n",
        "    def __len__(self): return len(self.bags)\n",
        "\n",
        "\n",
        "    # The method below is called whenever PyTorch asks for a sample.\n",
        "    # Retrieves the list of patch file paths for that bag.\n",
        "    def __getitem__(self, idx):\n",
        "        paths = self.bags[idx] # idx is the index of the bag you want.\n",
        "        imgs = []\n",
        "        for p in paths:   # Loops through each patch path in the bag.\n",
        "            try:\n",
        "                img = Image.open(p).convert('RGB')#Change the color transformation - YCbCr, HSV\n",
        "                if self.transform: # Applies transforms if provided (resize, normalize, etc.)\n",
        "                    img = self.transform(img)\n",
        "                imgs.append(img)\n",
        "            except:\n",
        "                continue #why try-except, what error? Why corrupt patches?\n",
        "        if len(imgs) == 0:\n",
        "            raise ValueError(f\"No usable patches in slice {paths}\")\n",
        "        if self.emergency_cap and len(imgs) > self.emergency_cap:\n",
        "            imgs = random.sample(imgs, self.emergency_cap)\n",
        "        return torch.stack(imgs), torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "        #Stacks all transformed image tensors into a single tensor of shape:\n",
        "        #(num_patches, C, H, W)\n",
        "        #(e.g., (500, 3, 224, 224) for 500 patches).\n",
        "        #Converts the label to a PyTorch tensor of type long (needed for classification loss).\n",
        "        #Returns (bag_tensor, label_tensor) as one sample.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AiL7l1Bmt0Aw"
      },
      "outputs": [],
      "source": [
        "# this pools the patch level features into single bag level representation for MIL\n",
        "class AttentionPool(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim=128):\n",
        "      #input_dim: the dimensionality of each input feature vector (e.g., 512 if you’re using a CNN encoder like ResNet).\n",
        "      #hidden_dim: the size of the hidden layer used inside the attention mechanism (default = 128).\n",
        "      #This defines how much capacity the attention sub-network has to learn complex relationships.\n",
        "        super().__init__()\n",
        "        # creates small neural network to compute attention scores for each patch\n",
        "        # each patch embedding is passed through a linear layer, tanh for nonlinearity, and another linear layer to get a scalar score\n",
        "        self.attention = nn.Sequential(\n",
        "            nn.Linear(input_dim, hidden_dim),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(hidden_dim, 1)\n",
        "        )\n",
        "    def forward(self, x, return_weights=False):\n",
        "        # x is of shape (B, M, D) where B is batch size or number of cases,\n",
        "        # M is number of patches per bag, and D is the embedding dimensions for each patch\n",
        "        weights = self.attention(x)     # (B, M, 1)\n",
        "        weights = torch.softmax(weights, dim=1) # softmax so that weights are positive\n",
        "        # outputs attention scores for each patch and normalized with softmax\n",
        "        # D is the embedding dimension which is size of feature vector for each patch after going through the patch classifier\n",
        "        weighted_x = (weights * x).sum(dim=1)  # (B, D)\n",
        "        # returning the raw attention weights per patch just to help with visualization of the weights for each patch\n",
        "        if return_weights:\n",
        "            return weighted_x, weights.squeeze(-1)  # (B, D), (B, M)\n",
        "        return weighted_x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPpCrdoE-zWB"
      },
      "source": [
        "# using Densenet to extract features at the patch-level, and adaptaive pooling for patch-level feature pooling\n",
        "# the patch features are passed into Attentionpool which learns the weights across patches and combines them into a single bag label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sqabQIV6-fo5"
      },
      "outputs": [],
      "source": [
        "class AttnMIL(nn.Module):\n",
        "    def __init__(self, base_model, num_classes=2, embed_dim=512):\n",
        "        super().__init__()\n",
        "        # grabbing the convolutional feature extractor from the pretrained model\n",
        "        self.features = base_model.features\n",
        "        # applying adaptive average pooling to compress to feature map of 2x2 grid\n",
        "        # you get 4 spatial vectors per patch\n",
        "        self.pool = nn.AdaptiveAvgPool2d((2,2))  # richer than (1,1) - tunable!\n",
        "        # meaning that you'll get 4 vectors per patch which will then be flattened\n",
        "        self.patch_projector = nn.Linear(base_model.classifier.in_features * 4, embed_dim)\n",
        "\n",
        "        # Attention module (your earlier class) that produces per-patch weights and returns a bag embedding (weighted sum) of size embed_dim.\n",
        "        self.attention_pool = AttentionPool(embed_dim)\n",
        "\n",
        "        # Final classifier that maps the bag embedding to logits over classes.\n",
        "        self.classifier = nn.Linear(embed_dim, num_classes)\n",
        "\n",
        "\n",
        "    def forward(self, x, return_patch_logits=False, return_attn_weights=False):\n",
        "        if x.dim() == 4: # why the need to check?\n",
        "            x = x.unsqueeze(0)\n",
        "        # typically after CNN you get 3D tensor with num channels, height and width of image\n",
        "        # but we packed the patches into a bag by case (the tensor), so B is batch size, M is number of patches per bag\n",
        "        B, M, C, H, W = x.shape\n",
        "        x = x.view(B*M, C, H, W) # put all patches in the batch together\n",
        "\n",
        "        features = self.features(x) # exxtracting cnn features for each patch, output shape: (B*M, C', H', W')\n",
        "        pooled = self.pool(features).view(B*M, -1) # pool each feature map to a 2x2 grid and flatten, output shape: (B*M, 4*C')\n",
        "        embedded = self.patch_projector(pooled).view(B, M, -1) # project each patch into shared embedding space, output shape (B, M, embed_dim)\n",
        "        # just ensuring all the patches are transformed into vectors of the same length for attention\n",
        "\n",
        "        # in order to get patch level predictions\n",
        "        # Optional per-patch logits: apply the bag classifier to each patch embedding independently. Shape (B, M, num_classes). Useful for diagnostics/auxiliary losses.\n",
        "        if return_patch_logits:\n",
        "            logits = self.classifier(embedded)  # (B, M, 2)\n",
        "            return logits\n",
        "        # returning attention weights for visualization\n",
        "        if return_attn_weights:\n",
        "            bag_emb, attn_weights = self.attention_pool(embedded, return_weights=True)\n",
        "            logits = self.classifier(bag_emb)\n",
        "            return logits, attn_weights  # bag prediction + per-patch attention scores, why logits here when returning at the end\n",
        "\n",
        "        # applying attention\n",
        "        #computing a weighted average of patch embeddings using attention, and then is passed through the classifier to get bag level prediction\n",
        "        bag_emb = self.attention_pool(embedded) #Shape: (B, embed_dim) + weights (B, M)\n",
        "        logits = self.classifier(bag_emb) # Shape: (B, 2)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6JuOK_etMoUL"
      },
      "source": [
        "# What is the effect of M varying in each bag?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ny2nqVDsMltd"
      },
      "outputs": [],
      "source": [
        "# Set up datasets\n",
        "# Set up slice-based MIL datasets\n",
        "# dict mapping slice_key -> list_of_patch_paths for the train split.\n",
        "# dict mapping slice_key -> class_label.\n",
        "# image augmentations for training (e.g., flips/crops/normalization).\n",
        "train_ds = SliceMILDataset(train_patches, slice_to_class, transform=train_transform)\n",
        "\n",
        "# Uses (usually) lighter or no augmentation (transform) to mimic evaluation conditions.\n",
        "val_ds   = SliceMILDataset(val_patches, slice_to_class, transform=transform)\n",
        "\n",
        "# emergency_cap=None disables the cap on patches per bag (use all patches). Helpful to evaluate full performance without subsampling.\n",
        "test_ds  = SliceMILDataset(test_patches, slice_to_class, transform=transform, emergency_cap=None)\n",
        "\n",
        "# help generalize better and reduce overfitting\n",
        "# Wraps train_ds in a PyTorch DataLoader.\n",
        "# batch_size=1: in MIL, each bag (slice) can contain a variable number of patches; batching multiple bags together often requires padding/collate tricks. Why? Is it because bag sizes are different? Using 1 bag per batch keeps it simple and memory-safe.\n",
        "# shuffle=True: randomizes bag order each epoch → improves generalization and reduces overfitting.\n",
        "train_loader = DataLoader(train_ds, batch_size=1, shuffle=True)\n",
        "# don't want to shuffle so taht you get consistent, repeatable evaluation\n",
        "val_loader   = DataLoader(val_ds, batch_size=1, shuffle=False)\n",
        "test_loader  = DataLoader(test_ds, batch_size=1, shuffle=False)\n",
        "\n",
        "# If bags vary wildly in size and you want larger batches, you can implement a custom collate_fn to pad/truncate bags, but that adds complexity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BMmsiT2-UuLK",
        "outputId": "242c73b9-00be-4790-ca1b-fa36f469f648"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "🔹 Train Split\n",
            "Cases: 197\n",
            "Patches: 23912\n",
            "Class distribution: {1: 109, 0: 88}\n",
            "Slices (unique IDs): 19\n",
            "\n",
            "🔹 Validation Split\n",
            "Cases: 60\n",
            "Patches: 7832\n",
            "Class distribution: {1: 44, 0: 16}\n",
            "Slices (unique IDs): 11\n",
            "\n",
            "🔹 Test Split\n",
            "Cases: 79\n",
            "Patches: 7993\n",
            "Class distribution: {1: 66, 0: 13}\n",
            "Slices (unique IDs): 31\n"
          ]
        }
      ],
      "source": [
        "def summarize_split(patch_dict, label_map=None, split_name=\"\"):\n",
        "    # Count cases\n",
        "    num_cases = len(patch_dict)\n",
        "\n",
        "    # Count total patches\n",
        "    total_patches = sum(len(paths) for paths in patch_dict.values())\n",
        "\n",
        "    # Count per class (if label map provided)\n",
        "    class_counts = Counter()\n",
        "    if label_map:\n",
        "        class_counts.update([label_map[c] for c in patch_dict.keys() if c in label_map])\n",
        "\n",
        "    # Count unique slice IDs (if present in patch filenames)\n",
        "    slice_set = set()\n",
        "    for paths in patch_dict.values():\n",
        "        for path in paths:\n",
        "            # Extract slice identifier after 2nd underscore (e.g., unmatched_2 from case_01_unmatched_2_patch43.png)\n",
        "            match = re.search(r\"case_\\d+_(\\w+_\\d+)\", os.path.basename(path))\n",
        "            if match:\n",
        "                slice_set.add(match.group(1))\n",
        "\n",
        "    # Output\n",
        "    print(f\"\\n🔹 {split_name} Split\")\n",
        "    print(f\"Cases: {num_cases}\")\n",
        "    print(f\"Patches: {total_patches}\")\n",
        "    if class_counts:\n",
        "        print(f\"Class distribution: {dict(class_counts)}\")\n",
        "    print(f\"Slices (unique IDs): {len(slice_set)}\")\n",
        "\n",
        "# Run for all splits\n",
        "summarize_split(train_patches, slice_to_class, split_name=\"Train\")\n",
        "summarize_split(val_patches, slice_to_class, split_name=\"Validation\")\n",
        "summarize_split(test_patches, slice_to_class, split_name=\"Test\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JrXxnvADF8HS"
      },
      "source": [
        "hannah's code below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SXqHMuXcFtzR",
        "outputId": "e5bc9f0f-9bf1-4609-b785-51f4c784be53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "📦 Patch counts for Train:\n",
            "  Case (1, 'match_1'): 64 patches\n",
            "  Case (1, 'unmatched_1'): 68 patches\n",
            "  Case (1, 'unmatched_2'): 74 patches\n",
            "  Case (1, 'unmatched_3'): 74 patches\n",
            "  Case (3, 'match_1'): 122 patches\n",
            "  Case (3, 'unmatched_1'): 70 patches\n",
            "  Case (3, 'unmatched_2'): 108 patches\n",
            "  Case (3, 'unmatched_3'): 192 patches\n",
            "  Case (4, 'match_1'): 124 patches\n",
            "  Case (4, 'unmatched_1'): 163 patches\n",
            "  Case (4, 'unmatched_2'): 233 patches\n",
            "  Case (5, 'match_1'): 142 patches\n",
            "  Case (5, 'unmatched_1'): 132 patches\n",
            "  Case (9, 'match_1'): 53 patches\n",
            "  Case (9, 'unmatched_1'): 50 patches\n",
            "  Case (9, 'unmatched_2'): 60 patches\n",
            "  Case (11, 'match_1'): 80 patches\n",
            "  Case (11, 'unmatched_1'): 95 patches\n",
            "  Case (11, 'unmatched_2'): 104 patches\n",
            "  Case (11, 'unmatched_3'): 46 patches\n",
            "  Case (14, 'match_1'): 120 patches\n",
            "  Case (14, 'match_3'): 58 patches\n",
            "  Case (14, 'match_4'): 88 patches\n",
            "  Case (14, 'unmatched_1'): 102 patches\n",
            "  Case (14, 'unmatched_2'): 72 patches\n",
            "  Case (14, 'unmatched_3'): 40 patches\n",
            "  Case (14, 'unmatched_4'): 62 patches\n",
            "  Case (16, 'match_1'): 177 patches\n",
            "  Case (18, 'match_1'): 137 patches\n",
            "  Case (18, 'unmatched_1'): 148 patches\n",
            "  Case (18, 'unmatched_2'): 136 patches\n",
            "  Case (18, 'unmatched_3'): 121 patches\n",
            "  Case (19, 'match_1'): 233 patches\n",
            "  Case (19, 'match_2'): 234 patches\n",
            "  Case (19, 'match_3'): 179 patches\n",
            "  Case (19, 'match_4'): 177 patches\n",
            "  Case (19, 'unmatched_1'): 153 patches\n",
            "  Case (19, 'unmatched_2'): 178 patches\n",
            "  Case (19, 'unmatched_3'): 225 patches\n",
            "  Case (19, 'unmatched_4'): 180 patches\n",
            "  Case (22, 'match_1'): 252 patches\n",
            "  Case (22, 'match_2'): 121 patches\n",
            "  Case (22, 'unmatched_1'): 113 patches\n",
            "  Case (22, 'unmatched_10'): 84 patches\n",
            "  Case (22, 'unmatched_11'): 105 patches\n",
            "  Case (22, 'unmatched_2'): 223 patches\n",
            "  Case (22, 'unmatched_3'): 128 patches\n",
            "  Case (22, 'unmatched_4'): 89 patches\n",
            "  Case (22, 'unmatched_5'): 32 patches\n",
            "  Case (22, 'unmatched_6'): 234 patches\n",
            "  Case (22, 'unmatched_7'): 96 patches\n",
            "  Case (22, 'unmatched_8'): 247 patches\n",
            "  Case (22, 'unmatched_9'): 248 patches\n",
            "  Case (23, 'unmatched_1'): 193 patches\n",
            "  Case (23, 'unmatched_2'): 169 patches\n",
            "  Case (23, 'unmatched_3'): 196 patches\n",
            "  Case (23, 'unmatched_4'): 164 patches\n",
            "  Case (24, 'match_1'): 191 patches\n",
            "  Case (24, 'match_2'): 128 patches\n",
            "  Case (24, 'unmatched_1'): 22 patches\n",
            "  Case (24, 'unmatched_2'): 132 patches\n",
            "  Case (24, 'unmatched_3'): 177 patches\n",
            "  Case (24, 'unmatched_4'): 43 patches\n",
            "  Case (24, 'unmatched_5'): 154 patches\n",
            "  Case (24, 'unmatched_6'): 184 patches\n",
            "  Case (24, 'unmatched_7'): 69 patches\n",
            "  Case (24, 'unmatched_8'): 107 patches\n",
            "  Case (25, 'match_1'): 94 patches\n",
            "  Case (25, 'match_2'): 110 patches\n",
            "  Case (25, 'unmatched_1'): 85 patches\n",
            "  Case (25, 'unmatched_2'): 98 patches\n",
            "  Case (25, 'unmatched_3'): 105 patches\n",
            "  Case (25, 'unmatched_4'): 120 patches\n",
            "  Case (26, 'match_1'): 161 patches\n",
            "  Case (26, 'match_2'): 113 patches\n",
            "  Case (26, 'match_3'): 40 patches\n",
            "  Case (26, 'unmatched_1'): 166 patches\n",
            "  Case (26, 'unmatched_10'): 28 patches\n",
            "  Case (26, 'unmatched_11'): 208 patches\n",
            "  Case (26, 'unmatched_12'): 52 patches\n",
            "  Case (26, 'unmatched_13'): 62 patches\n",
            "  Case (26, 'unmatched_14'): 201 patches\n",
            "  Case (26, 'unmatched_2'): 28 patches\n",
            "  Case (26, 'unmatched_3'): 81 patches\n",
            "  Case (26, 'unmatched_4'): 158 patches\n",
            "  Case (26, 'unmatched_5'): 26 patches\n",
            "  Case (26, 'unmatched_6'): 122 patches\n",
            "  Case (26, 'unmatched_7'): 35 patches\n",
            "  Case (26, 'unmatched_8'): 92 patches\n",
            "  Case (26, 'unmatched_9'): 159 patches\n",
            "  Case (27, 'match_1'): 72 patches\n",
            "  Case (27, 'unmatched_2'): 56 patches\n",
            "  Case (27, 'unmatched_3'): 77 patches\n",
            "  Case (27, 'unmatched_4'): 80 patches\n",
            "  Case (27, 'unmatched_5'): 92 patches\n",
            "  Case (27, 'unmatched_7'): 114 patches\n",
            "  Case (28, 'match_1'): 185 patches\n",
            "  Case (28, 'unmatched_1'): 26 patches\n",
            "  Case (28, 'unmatched_2'): 152 patches\n",
            "  Case (28, 'unmatched_3'): 194 patches\n",
            "  Case (28, 'unmatched_4'): 82 patches\n",
            "  Case (36, 'match_1'): 77 patches\n",
            "  Case (36, 'match_2'): 71 patches\n",
            "  Case (36, 'unmatched_1'): 63 patches\n",
            "  Case (36, 'unmatched_2'): 49 patches\n",
            "  Case (36, 'unmatched_3'): 63 patches\n",
            "  Case (40, 'match_1'): 86 patches\n",
            "  Case (40, 'match_2'): 31 patches\n",
            "  Case (40, 'match_3'): 42 patches\n",
            "  Case (40, 'match_4'): 169 patches\n",
            "  Case (41, 'match_1'): 166 patches\n",
            "  Case (41, 'match_2'): 192 patches\n",
            "  Case (41, 'match_3'): 38 patches\n",
            "  Case (41, 'match_4'): 57 patches\n",
            "  Case (41, 'match_5'): 105 patches\n",
            "  Case (42, 'match_1'): 115 patches\n",
            "  Case (42, 'match_2'): 28 patches\n",
            "  Case (44, 'match_1'): 156 patches\n",
            "  Case (44, 'match_2'): 186 patches\n",
            "  Case (45, 'match_1'): 48 patches\n",
            "  Case (46, 'match_1'): 51 patches\n",
            "  Case (49, 'match_1'): 46 patches\n",
            "  Case (51, 'match_1'): 190 patches\n",
            "  Case (51, 'match_2'): 75 patches\n",
            "  Case (52, 'match_1'): 176 patches\n",
            "  Case (56, 'match_1'): 66 patches\n",
            "  Case (56, 'match_2'): 74 patches\n",
            "  Case (57, 'match_1'): 43 patches\n",
            "  Case (57, 'match_2'): 176 patches\n",
            "  Case (57, 'match_3'): 195 patches\n",
            "  Case (59, 'match_1'): 117 patches\n",
            "  Case (60, 'match_1'): 345 patches\n",
            "  Case (64, 'match_1'): 336 patches\n",
            "  Case (64, 'match_2'): 71 patches\n",
            "  Case (64, 'match_3'): 67 patches\n",
            "  Case (64, 'match_4'): 73 patches\n",
            "  Case (66, 'match_1'): 120 patches\n",
            "  Case (66, 'match_2'): 41 patches\n",
            "  Case (66, 'match_3'): 28 patches\n",
            "  Case (66, 'match_4'): 23 patches\n",
            "  Case (67, 'match_1'): 33 patches\n",
            "  Case (68, 'match_1'): 120 patches\n",
            "  Case (68, 'match_2'): 21 patches\n",
            "  Case (68, 'match_3'): 22 patches\n",
            "  Case (69, 'match_1'): 111 patches\n",
            "  Case (69, 'match_2'): 23 patches\n",
            "  Case (69, 'match_3'): 11 patches\n",
            "  Case (69, 'match_4'): 37 patches\n",
            "  Case (77, 'match_1'): 98 patches\n",
            "  Case (77, 'unmatched_1'): 49 patches\n",
            "  Case (80, 'match_1'): 164 patches\n",
            "  Case (80, 'unmatched_1'): 142 patches\n",
            "  Case (82, 'match_1'): 255 patches\n",
            "  Case (82, 'unmatched_1'): 138 patches\n",
            "  Case (82, 'unmatched_2'): 143 patches\n",
            "  Case (82, 'unmatched_3'): 148 patches\n",
            "  Case (82, 'unmatched_4'): 218 patches\n",
            "  Case (82, 'unmatched_5'): 189 patches\n",
            "  Case (83, 'match_1'): 453 patches\n",
            "  Case (83, 'unmatched_1'): 109 patches\n",
            "  Case (83, 'unmatched_2'): 186 patches\n",
            "  Case (83, 'unmatched_3'): 222 patches\n",
            "  Case (83, 'unmatched_4'): 230 patches\n",
            "  Case (83, 'unmatched_5'): 272 patches\n",
            "  Case (85, 'match_1'): 114 patches\n",
            "  Case (85, 'unmatched_1'): 58 patches\n",
            "  Case (85, 'unmatched_2'): 76 patches\n",
            "  Case (87, 'match_1'): 167 patches\n",
            "  Case (87, 'unmatched_1'): 220 patches\n",
            "  Case (88, 'match_1'): 60 patches\n",
            "  Case (88, 'unmatched_1'): 21 patches\n",
            "  Case (88, 'unmatched_2'): 19 patches\n",
            "  Case (89, 'match_1'): 194 patches\n",
            "  Case (89, 'unmatched_1'): 129 patches\n",
            "  Case (94, 'match_1'): 187 patches\n",
            "  Case (94, 'unmatched_1'): 161 patches\n",
            "  Case (95, 'match_1'): 142 patches\n",
            "  Case (95, 'unmatched_1'): 74 patches\n",
            "  Case (96, 'match_1'): 268 patches\n",
            "  Case (96, 'unmatched_1'): 125 patches\n",
            "  Case (97, 'match_1'): 121 patches\n",
            "  Case (97, 'match_2'): 90 patches\n",
            "  Case (97, 'match_3'): 81 patches\n",
            "  Case (97, 'match_4'): 160 patches\n",
            "  Case (97, 'unmatched_10'): 77 patches\n",
            "  Case (97, 'unmatched_11'): 235 patches\n",
            "  Case (97, 'unmatched_5'): 97 patches\n",
            "  Case (97, 'unmatched_6'): 112 patches\n",
            "  Case (97, 'unmatched_7'): 136 patches\n",
            "  Case (97, 'unmatched_8'): 253 patches\n",
            "  Case (97, 'unmatched_9'): 134 patches\n",
            "  Case (99, 'match_1'): 61 patches\n",
            "  Case (99, 'unmatched_1'): 72 patches\n",
            "  Case (100, 'match_1'): 150 patches\n",
            "  Case (100, 'unmatched_1'): 161 patches\n",
            "  Case (106, 'match_1'): 165 patches\n",
            "  Case (106, 'unmatched_1'): 94 patches\n",
            "\n",
            "📦 Patch counts for Validation:\n",
            "  Case (7, 'match_1'): 117 patches\n",
            "  Case (7, 'unmatched_1'): 87 patches\n",
            "  Case (7, 'unmatched_2'): 118 patches\n",
            "  Case (12, 'match_1'): 50 patches\n",
            "  Case (12, 'unmatched_1'): 104 patches\n",
            "  Case (12, 'unmatched_2'): 108 patches\n",
            "  Case (15, 'unmatched_1'): 27 patches\n",
            "  Case (15, 'unmatched_2'): 171 patches\n",
            "  Case (15, 'unmatched_3'): 90 patches\n",
            "  Case (15, 'unmatched_4'): 15 patches\n",
            "  Case (15, 'unmatched_5'): 203 patches\n",
            "  Case (15, 'unmatched_6'): 73 patches\n",
            "  Case (15, 'unmatched_8'): 132 patches\n",
            "  Case (15, 'unmatched_9'): 173 patches\n",
            "  Case (21, 'unmatched_1'): 109 patches\n",
            "  Case (21, 'unmatched_2'): 151 patches\n",
            "  Case (21, 'unmatched_3'): 178 patches\n",
            "  Case (30, 'match_1'): 161 patches\n",
            "  Case (30, 'unmatched_1'): 72 patches\n",
            "  Case (30, 'unmatched_2'): 97 patches\n",
            "  Case (32, 'match_1'): 56 patches\n",
            "  Case (32, 'unmatched_1'): 50 patches\n",
            "  Case (32, 'unmatched_2'): 50 patches\n",
            "  Case (32, 'unmatched_3'): 53 patches\n",
            "  Case (34, 'match_1'): 101 patches\n",
            "  Case (34, 'unmatched_1'): 97 patches\n",
            "  Case (34, 'unmatched_2'): 31 patches\n",
            "  Case (34, 'unmatched_3'): 82 patches\n",
            "  Case (47, 'match_1'): 465 patches\n",
            "  Case (50, 'match_1'): 21 patches\n",
            "  Case (50, 'match_2'): 365 patches\n",
            "  Case (50, 'match_3'): 335 patches\n",
            "  Case (72, 'match_1'): 60 patches\n",
            "  Case (72, 'unmatched_1'): 10 patches\n",
            "  Case (72, 'unmatched_2'): 39 patches\n",
            "  Case (72, 'unmatched_3'): 106 patches\n",
            "  Case (72, 'unmatched_4'): 5 patches\n",
            "  Case (73, 'match_1'): 500 patches\n",
            "  Case (73, 'unmatched_1'): 167 patches\n",
            "  Case (73, 'unmatched_2'): 105 patches\n",
            "  Case (75, 'match_1'): 202 patches\n",
            "  Case (75, 'unmatched_1'): 227 patches\n",
            "  Case (84, 'match_1'): 239 patches\n",
            "  Case (84, 'unmatched_1'): 139 patches\n",
            "  Case (84, 'unmatched_2'): 124 patches\n",
            "  Case (84, 'unmatched_3'): 151 patches\n",
            "  Case (84, 'unmatched_4'): 107 patches\n",
            "  Case (84, 'unmatched_5'): 108 patches\n",
            "  Case (86, 'match_1'): 102 patches\n",
            "  Case (86, 'match_2'): 152 patches\n",
            "  Case (86, 'unmatched_1'): 121 patches\n",
            "  Case (86, 'unmatched_2'): 146 patches\n",
            "  Case (90, 'match_1'): 123 patches\n",
            "  Case (90, 'unmatched_1'): 146 patches\n",
            "  Case (91, 'match_1'): 46 patches\n",
            "  Case (91, 'match_2'): 66 patches\n",
            "  Case (91, 'unmatched_1'): 77 patches\n",
            "  Case (91, 'unmatched_2'): 76 patches\n",
            "  Case (101, 'match_1'): 328 patches\n",
            "  Case (101, 'unmatched_1'): 218 patches\n",
            "\n",
            "📦 Patch counts for Test:\n",
            "  Case (2, 'match_1'): 124 patches\n",
            "  Case (2, 'unmatched_1'): 100 patches\n",
            "  Case (2, 'unmatched_2'): 114 patches\n",
            "  Case (2, 'unmatched_3'): 99 patches\n",
            "  Case (17, 'match_1'): 104 patches\n",
            "  Case (17, 'unmatched_2'): 59 patches\n",
            "  Case (17, 'unmatched_3'): 70 patches\n",
            "  Case (38, 'match_1'): 69 patches\n",
            "  Case (38, 'match_10'): 112 patches\n",
            "  Case (38, 'match_11'): 52 patches\n",
            "  Case (38, 'match_12'): 37 patches\n",
            "  Case (38, 'match_13'): 31 patches\n",
            "  Case (38, 'match_14'): 43 patches\n",
            "  Case (38, 'match_15'): 23 patches\n",
            "  Case (38, 'match_24'): 27 patches\n",
            "  Case (38, 'match_25'): 22 patches\n",
            "  Case (38, 'match_26'): 28 patches\n",
            "  Case (38, 'match_31'): 46 patches\n",
            "  Case (38, 'match_7'): 218 patches\n",
            "  Case (38, 'match_8'): 118 patches\n",
            "  Case (38, 'match_9'): 314 patches\n",
            "  Case (43, 'match_1'): 160 patches\n",
            "  Case (48, 'match_1'): 132 patches\n",
            "  Case (48, 'match_2'): 199 patches\n",
            "  Case (53, 'match_1'): 179 patches\n",
            "  Case (54, 'match_1'): 135 patches\n",
            "  Case (54, 'match_2'): 78 patches\n",
            "  Case (55, 'match_1'): 151 patches\n",
            "  Case (55, 'match_2'): 124 patches\n",
            "  Case (58, 'match_1'): 273 patches\n",
            "  Case (61, 'match_1'): 295 patches\n",
            "  Case (63, 'match_1'): 9 patches\n",
            "  Case (63, 'match_2'): 54 patches\n",
            "  Case (63, 'match_3'): 64 patches\n",
            "  Case (63, 'match_4'): 17 patches\n",
            "  Case (63, 'match_5'): 41 patches\n",
            "  Case (63, 'match_6'): 3 patches\n",
            "  Case (63, 'match_7'): 8 patches\n",
            "  Case (70, 'match_1'): 78 patches\n",
            "  Case (70, 'match_2'): 30 patches\n",
            "  Case (70, 'match_3'): 30 patches\n",
            "  Case (70, 'match_4'): 67 patches\n",
            "  Case (70, 'match_5'): 112 patches\n",
            "  Case (70, 'match_6'): 39 patches\n",
            "  Case (78, 'match_1'): 151 patches\n",
            "  Case (78, 'unmatched_1'): 29 patches\n",
            "  Case (79, 'match_1'): 166 patches\n",
            "  Case (79, 'match_2'): 160 patches\n",
            "  Case (79, 'match_3'): 133 patches\n",
            "  Case (92, 'match_1'): 173 patches\n",
            "  Case (93, 'match_1'): 174 patches\n",
            "  Case (93, 'unmatched_1'): 117 patches\n",
            "  Case (98, 'match_1'): 305 patches\n",
            "  Case (98, 'unmatched_1'): 69 patches\n",
            "  Case (98, 'unmatched_2'): 174 patches\n",
            "  Case (104, 'match_1'): 169 patches\n",
            "  Case (104, 'match_12'): 17 patches\n",
            "  Case (104, 'match_13'): 58 patches\n",
            "  Case (104, 'match_2'): 101 patches\n",
            "  Case (104, 'match_3'): 69 patches\n",
            "  Case (104, 'match_4'): 166 patches\n",
            "  Case (104, 'match_6'): 367 patches\n",
            "  Case (104, 'match_7'): 48 patches\n",
            "  Case (104, 'match_8'): 153 patches\n",
            "  Case (104, 'match_9'): 155 patches\n",
            "  Case (104, 'unmatched_1'): 161 patches\n",
            "  Case (104, 'unmatched_10'): 15 patches\n",
            "  Case (104, 'unmatched_11'): 48 patches\n",
            "  Case (104, 'unmatched_12'): 45 patches\n",
            "  Case (104, 'unmatched_13'): 56 patches\n",
            "  Case (104, 'unmatched_14'): 28 patches\n",
            "  Case (104, 'unmatched_2'): 76 patches\n",
            "  Case (104, 'unmatched_3'): 66 patches\n",
            "  Case (104, 'unmatched_4'): 125 patches\n",
            "  Case (104, 'unmatched_5'): 52 patches\n",
            "  Case (104, 'unmatched_6'): 98 patches\n",
            "  Case (104, 'unmatched_7'): 17 patches\n",
            "  Case (104, 'unmatched_8'): 114 patches\n",
            "  Case (104, 'unmatched_9'): 50 patches\n"
          ]
        }
      ],
      "source": [
        "def summarize_patch_distribution(patch_dict, split_name):\n",
        "    patch_counts = {case: len(patches) for case, patches in patch_dict.items()}\n",
        "    print(f\"\\n📦 Patch counts for {split_name}:\")\n",
        "    for case, count in sorted(patch_counts.items()):\n",
        "        print(f\"  Case {case}: {count} patches\")\n",
        "\n",
        "    df = pd.DataFrame(list(patch_counts.items()), columns=[\"Case\", \"Patch Count\"])\n",
        "    df.to_csv(f\"{split_name.lower()}_patch_counts.csv\", index=False)\n",
        "    return df\n",
        "\n",
        "# Call for each split\n",
        "train_df = summarize_patch_distribution(train_patches, \"Train\")\n",
        "val_df   = summarize_patch_distribution(val_patches, \"Validation\")\n",
        "test_df  = summarize_patch_distribution(test_patches, \"Test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AeQmu9nRGBT0",
        "outputId": "3a550d6a-3989-4da0-eafa-fc6b02b21ac6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "🧬 Patch count by class for Train:\n",
            "  Benign (0):     10684 patches\n",
            "  High-grade (1): 13228 patches\n",
            "\n",
            "🧬 Patch count by class for Validation:\n",
            "  Benign (0):     1869 patches\n",
            "  High-grade (1): 5963 patches\n",
            "\n",
            "🧬 Patch count by class for Test:\n",
            "  Benign (0):     1706 patches\n",
            "  High-grade (1): 6287 patches\n"
          ]
        }
      ],
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "def count_patches_by_class(patch_dict, case_to_class, split_name):\n",
        "    class_patch_counts = defaultdict(int)\n",
        "\n",
        "    for case, patches in patch_dict.items():\n",
        "        label = case_to_class[case]\n",
        "        class_patch_counts[label] += len(patches)\n",
        "\n",
        "    print(f\"\\n🧬 Patch count by class for {split_name}:\")\n",
        "    print(f\"  Benign (0):     {class_patch_counts[0]} patches\")\n",
        "    print(f\"  High-grade (1): {class_patch_counts[1]} patches\")\n",
        "\n",
        "    return class_patch_counts\n",
        "\n",
        "# Count patches per class for each split\n",
        "train_counts = count_patches_by_class(train_patches, slice_to_class, \"Train\")\n",
        "val_counts   = count_patches_by_class(val_patches, slice_to_class, \"Validation\")\n",
        "test_counts  = count_patches_by_class(test_patches, slice_to_class, \"Test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c7SXpMFEGH6_"
      },
      "outputs": [],
      "source": [
        "def save_checkpoint_to_drive(model, arch, optimizer, epoch, drive_folder=\"MyDrive/Checkpoints\"):\n",
        "    checkpoint_dir = os.path.join(\"/content/drive\", drive_folder)\n",
        "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    filename = f\"{checkpoint_dir}/{timestamp}_{arch}_epoch{epoch}.pth\"\n",
        "\n",
        "    checkpoint = {\n",
        "        \"arch\": arch,\n",
        "        \"model_state_dict\": model.state_dict(),\n",
        "        \"epoch\": epoch,\n",
        "        \"optimizer_state_dict\": optimizer.state_dict(),\n",
        "    }\n",
        "\n",
        "    torch.save(checkpoint, filename)\n",
        "    print(f\"✅ Checkpoint saved to Google Drive: {filename}\")\n",
        "\n",
        "def validation(model, criterion, val_loader):\n",
        "    val_loss = 0\n",
        "    correct_total = 0\n",
        "    sample_total = 0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for bags, labels in val_loader:\n",
        "            bags = bags.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(bags)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item() * labels.size(0)\n",
        "            preds = torch.argmax(outputs, dim=1)\n",
        "            correct_total += (preds == labels).sum().item()\n",
        "            sample_total += labels.size(0)\n",
        "    return val_loss / sample_total, correct_total / sample_total\n",
        "\n",
        "# def train_model(model, optimizer, criterion, train_loader, val_loader, arch, checkpoint_dir, epochs=5):\n",
        "def train_model(model, optimizer, criterion, train_loader, val_loader, arch, epochs=5, start_epoch=0):\n",
        "    for epoch in range(start_epoch, epochs):\n",
        "        model.train()\n",
        "        running_loss = 0\n",
        "        for bags, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
        "            bags = bags.to(device)\n",
        "            labels = labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(bags)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "        val_loss, val_acc = validation(model, criterion, val_loader)\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {running_loss/len(train_loader):.3f}, Val Loss: {val_loss:.3f}, Val Acc: {val_acc:.3f}\")\n",
        "        save_checkpoint_to_drive(model, arch, optimizer, epoch+1, drive_folder=\"MyDrive/Checkpoints\")\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWZp9d6sGIw5",
        "outputId": "99766066-585e-4e87-8b81-abf1010aa8dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/densenet121-a639ec97.pth\" to /root/.cache/torch/hub/checkpoints/densenet121-a639ec97.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 30.8M/30.8M [00:00<00:00, 120MB/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "PatchClassifier(\n",
              "  (features): Sequential(\n",
              "    (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "    (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu0): ReLU(inplace=True)\n",
              "    (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "    (denseblock1): _DenseBlock(\n",
              "      (denselayer1): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer2): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer3): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer4): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer5): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer6): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (transition1): _Transition(\n",
              "      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "    )\n",
              "    (denseblock2): _DenseBlock(\n",
              "      (denselayer1): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer2): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer3): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer4): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer5): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer6): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer7): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer8): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer9): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer10): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer11): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer12): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (transition2): _Transition(\n",
              "      (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "    )\n",
              "    (denseblock3): _DenseBlock(\n",
              "      (denselayer1): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer2): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer3): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer4): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer5): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer6): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer7): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer8): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer9): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer10): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer11): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer12): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer13): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer14): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer15): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer16): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer17): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer18): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer19): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer20): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer21): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer22): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer23): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer24): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (transition3): _Transition(\n",
              "      (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "    )\n",
              "    (denseblock4): _DenseBlock(\n",
              "      (denselayer1): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer2): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer3): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer4): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer5): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer6): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer7): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer8): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer9): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer10): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer11): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer12): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer13): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer14): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer15): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (denselayer16): _DenseLayer(\n",
              "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu1): ReLU(inplace=True)\n",
              "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu2): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (norm5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (pool): AdaptiveAvgPool2d(output_size=(2, 2))\n",
              "  (classifier): Linear(in_features=4096, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# ------------------- Load pretrained patch model -------------------\n",
        "# used for classifiing individual image patches, its convolutional layers are used as frozen feature extractor in MIL\n",
        "class PatchClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        base = models.densenet121(weights=models.DenseNet121_Weights.DEFAULT)\n",
        "        # loading the pre trained densenet model\n",
        "        self.features = base.features\n",
        "        # compress final convolutional output of each image to 2x2 feature map\n",
        "        self.pool = nn.AdaptiveAvgPool2d((2,2))\n",
        "        self.classifier = nn.Linear(base.classifier.in_features * 4, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # first passes input images through Densenet convolutional layers to get feature maps\n",
        "        x = self.features(x)\n",
        "        # applies pooling\n",
        "        x = self.pool(x).view(x.size(0), -1)\n",
        "        # passes to final classifier layer to get the logits\n",
        "        return self.classifier(x)\n",
        "\n",
        "patch_model = PatchClassifier()\n",
        "# patch_model.load_state_dict(torch.load(os.path.join(filtered_patches_dir, \"patch_classifier.pth\")))\n",
        "patch_model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dMwYAbgEInNZ"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# ------------------- Inject backbone into MIL -------------------\n",
        "# creating new densenet model with no pretrained weights\n",
        "base_model = models.densenet121(weights=None)\n",
        "# replacing its features or convolutional layers with the pretrained ones from the patch classifier that we loaded\n",
        "base_model.features = patch_model.features\n",
        "\n",
        "# creating the Attention MIL model using the pretrained feature extractor\n",
        "model = AttnMIL(base_model=base_model).to(device)\n",
        "# freezing the feature extractor\n",
        "for param in model.features.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "arch = \"densenet121_simplemil\"\n",
        "\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=1, shuffle=True)\n",
        "val_loader = DataLoader(val_ds, batch_size=1, shuffle=False)\n",
        "test_loader = DataLoader(test_ds, batch_size=1, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KK6EcRwwGKCq"
      },
      "outputs": [],
      "source": [
        "# function to load the lastest checkpoint\n",
        "def load_checkpoint(checkpoint_path, model, optimizer):\n",
        "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    start_epoch = checkpoint['epoch']\n",
        "    print(f\"✅ Loaded checkpoint from epoch {start_epoch}\")\n",
        "    return model, optimizer, start_epoch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oTg7a7buEdda",
        "outputId": "a8634337-0a7b-4ae9-f40d-58fb8ff75174"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Loaded checkpoint from epoch 2\n"
          ]
        }
      ],
      "source": [
        "# load the lastest epoch (if connection failed)\n",
        "checkpoint_path = \"/content/drive/MyDrive/Checkpoints/20251020_122922_densenet121_simplemil_epoch2.pth\"\n",
        "model, optimizer, start_epoch = load_checkpoint(checkpoint_path, model, optimizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D8-VduK5I07K",
        "outputId": "99c9598c-180e-4266-afa1-ea3a4f036e68"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/5:  11%|█         | 22/197 [35:04<5:17:22, 108.81s/it]"
          ]
        }
      ],
      "source": [
        "train_model(model, optimizer, criterion, train_loader, val_loader, arch, epochs=5, start_epoch=start_epoch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1MsSkfMOIu6_"
      },
      "outputs": [],
      "source": [
        "# ------------------- Evaluation -------------------\n",
        "model.eval()\n",
        "all_preds, all_trues = [], []\n",
        "all_patch_preds, all_patch_trues = [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for X_bag, y in test_loader:\n",
        "        X_bag, y = X_bag.to(device), y.to(device)\n",
        "\n",
        "        # Case-level prediction\n",
        "        bag_logits = model(X_bag)\n",
        "        bag_pred = bag_logits.argmax(dim=1)\n",
        "        all_preds.extend(bag_pred.cpu().numpy())\n",
        "        all_trues.extend(y.cpu().numpy())\n",
        "\n",
        "        # Patch-level prediction (weak supervision)\n",
        "        patch_logits = model(X_bag, return_patch_logits=True)\n",
        "        patch_pred = patch_logits.argmax(dim=2).squeeze(0).cpu().numpy()\n",
        "        patch_labels = y.cpu().item() * np.ones_like(patch_pred)\n",
        "\n",
        "        all_patch_preds.extend(patch_pred)\n",
        "        all_patch_trues.extend(patch_labels)\n",
        "\n",
        "# Reports\n",
        "print(\"=== Slice-Level Classification Report ===\")\n",
        "print(classification_report(all_trues, all_preds, target_names=['Benign', 'High-grade CMIL'], labels=[0,1]))\n",
        "\n",
        "print(\"\\n=== Patch-Level Classification Report (weak labels) ===\")\n",
        "print(classification_report(all_patch_trues, all_patch_preds, target_names=['Benign', 'High-grade CMIL'], labels=[0,1]))\n",
        "\n",
        "# Confusion matrices\n",
        "for name, preds, trues in [\n",
        "    (\"Slice-Level\", all_preds, all_trues),\n",
        "    (\"Patch-Level\", all_patch_preds, all_patch_trues)\n",
        "]:\n",
        "    cm = confusion_matrix(trues, preds)\n",
        "    plt.figure(figsize=(6,5))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=['Benign','High-grade CMIL'],\n",
        "                yticklabels=['Benign','High-grade CMIL'])\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"True\")\n",
        "    plt.title(f\"{name} Confusion Matrix\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nqNB9su3I1w-"
      },
      "outputs": [],
      "source": [
        "\n",
        "from collections import defaultdict\n",
        "\n",
        "# Rebuild mapping from test set index to case_id\n",
        "slice_keys = list(test_patches.keys())  # keys like (case_id, slice_id)\n",
        "\n",
        "# Store per-slice predictions and truths\n",
        "case_preds = defaultdict(list)\n",
        "case_trues = {}\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i, (X_bag, y) in enumerate(test_loader):\n",
        "        X_bag, y = X_bag.to(device), y.to(device)\n",
        "        logits = model(X_bag)\n",
        "        pred = logits.argmax(dim=1).item()\n",
        "\n",
        "        case_id = slice_keys[i][0]  # extract case_id from (case_id, slice_id)\n",
        "        case_preds[case_id].append(pred)\n",
        "        case_trues[case_id] = y.item()  # same for all slices of this case\n",
        "\n",
        "# Majority vote per case\n",
        "final_preds = []\n",
        "final_trues = []\n",
        "for case_id in sorted(case_preds.keys()):\n",
        "    votes = case_preds[case_id]\n",
        "    maj_pred = max(set(votes), key=votes.count)\n",
        "    final_preds.append(maj_pred)\n",
        "    final_trues.append(case_trues[case_id])\n",
        "\n",
        "# Report\n",
        "print(\"=== Aggregated Case-Level Classification Report ===\")\n",
        "print(classification_report(final_trues, final_preds, target_names=['Benign', 'High-grade CMIL']))\n",
        "\n",
        "cm = confusion_matrix(final_trues, final_preds)\n",
        "plt.figure(figsize=(6,5))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=['Benign','High-grade CMIL'],\n",
        "            yticklabels=['Benign','High-grade CMIL'])\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.title(\"Aggregated Case-Level Confusion Matrix (Majority Vote)\")\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
